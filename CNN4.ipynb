{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:37:47.535714Z",
     "start_time": "2019-11-26T22:37:44.799814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# image processing\n",
    "from PIL import Image\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "# dataset processing, ml models and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:37:47.541724Z",
     "start_time": "2019-11-26T22:37:47.538707Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_ = 'HASYv2/'\n",
    "model_dir = 'trained_models/'\n",
    "data_dir = 'data/'\n",
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(data_dir + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    # Only process if image has transparency \n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL \n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "\n",
    "    else:\n",
    "        return im\n",
    "\n",
    "def change_to_bw(im):\n",
    "    for i in range(im.shape[0]):\n",
    "        for j in range(im.shape[1]):\n",
    "            if im[i][j] > 191.25:\n",
    "                im[i][j] = 0.0\n",
    "            else:\n",
    "                im[i][j] = 255.0\n",
    "    return im\n",
    "    \n",
    "def preprocess_img(path):\n",
    "    # Open Image\n",
    "    im = Image.open(dir_ + path)\n",
    "    \n",
    "    # Resize image to 32 by 32\n",
    "    if im.size != (32,32):\n",
    "        im = im.resize((32,32))\n",
    "        \n",
    "    # Convert image to a single greyscale channel\n",
    "    im = remove_transparency(im).convert('L')\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    I = np.array(im)\n",
    "    \n",
    "    #Close image\n",
    "    im.close()\n",
    "    I = change_to_bw(I)\n",
    "    return I\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preprocessing and Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_images(dataset):\n",
    "    temp = []\n",
    "    for i in range(len(dataset)):\n",
    "        if i % 10000 == 0:  \n",
    "            print(i)\n",
    "        path = dataset.iloc[i]['path']\n",
    "        pathsplit = path.split('/')\n",
    "        if len(pathsplit) > 2:\n",
    "            path = '/'.join([pathsplit[-2],pathsplit[-1]])\n",
    "        img = preprocess_img(path)\n",
    "        temp.append(img)\n",
    "    dataset['img'] = [i for i in temp]\n",
    "    return dataset\n",
    "\n",
    "def convert_to_one_hot_encode(data, no_categories):\n",
    "    data = np.array(data).reshape(-1)\n",
    "    print('len of dataset', len(data))\n",
    "    return np.eye(no_categories)[data]\n",
    "\n",
    "# to process output to the value\n",
    "# returns a list with all the categories with more than 50% accuracy\n",
    "def one_hot_encode_to_char(arr, threshold=0.5, get_max=True):\n",
    "    result = []\n",
    "    val = 0\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] >= threshold:\n",
    "            result.append((val, arr[i]))\n",
    "        val +=1\n",
    "    _max = []\n",
    "    high = 0\n",
    "    if get_max:\n",
    "        for i in result:\n",
    "            if i[1] > high:\n",
    "                _max = [i[0]]\n",
    "                high = i[1]\n",
    "        return _max\n",
    "    else:\n",
    "        return [i[0] for i in result]\n",
    "\n",
    "def convert_pred_list_ohe_to_labels(pred_data, threshold=0.5, get_max=True):\n",
    "    result = []\n",
    "    for i in range(len(pred_data)):\n",
    "        val = one_hot_encode_to_char(pred_data[i], threshold=threshold, get_max=get_max)\n",
    "        if len(val) > 0:\n",
    "            if get_max == True:\n",
    "                result.append(val[0])\n",
    "            else:\n",
    "                result.append(val)\n",
    "        else:\n",
    "            result.append(None)\n",
    "            print(\":( :( :(\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Train Test Split (new function)\n",
    "def get_df_split(ds, stratify_col, test_size=0.2):\n",
    "    _train, _test = train_test_split(ds, test_size=test_size, stratify=ds[stratify_col])\n",
    "    return _train, _test\n",
    "\n",
    "# function to split whole dataset at once (old function)\n",
    "def gen_x_y_train_test_stratified_1df(dataset, input_shape, test_size=0.2):\n",
    "    x = np.array(list(dataset['img']))\n",
    "    y = np.array(list(dataset['symbol_id_ohe']))\n",
    "    x = x.reshape((x.shape[0],1,input_shape[1],input_shape[2]))\n",
    "    # Normalize data to 0-1\n",
    "    x = x.astype(\"float32\") / 255.0\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size,  stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function to process already split data\n",
    "def process_x_y_train_test_stratified_2df(_tr, _ts, input_shape):\n",
    "    # train df\n",
    "    X_train = np.array(list(_tr['img']))\n",
    "    y_train = np.array(list(_tr['symbol_id_ohe']))\n",
    "    X_train = X_train.reshape((X_train.shape[0],1,input_shape[1],input_shape[2]))\n",
    "    # Normalize data to 0-1\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    # test df\n",
    "    X_test = np.array(list(_ts['img']))\n",
    "    y_test = np.array(list(_ts['symbol_id_ohe']))\n",
    "    X_test = X_test.reshape((X_test.shape[0],1,input_shape[1],input_shape[2]))\n",
    "    # Normalize data to 0-1\n",
    "    X_test = X_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate label counts for dataframe and list\n",
    "def get_label_count_df(df_train, df_test, sym_list):\n",
    "    train_labels_count = {}\n",
    "    test_labels_count = {}\n",
    "    perc_labels_count = {}\n",
    "    for i in sym_list:\n",
    "        train_labels_count[i] = 0\n",
    "        test_labels_count[i] = 0\n",
    "    for i in range(len(df_train)):\n",
    "        train_labels_count[df_train.loc[i,'symbol_id']] += 1\n",
    "    for i in range(len(df_test)):\n",
    "        test_labels_count[df_test.loc[i,'symbol_id']] += 1\n",
    "    for i in sym_list:\n",
    "        perc = (train_labels_count[i] / (train_labels_count[i] + test_labels_count[i])) * 100\n",
    "        perc_labels_count[i] = (train_labels_count[i], test_labels_count[i], round(perc,2))\n",
    "    return perc_labels_count\n",
    "\n",
    "def get_label_count_list(lst_data, sym_list):\n",
    "    labels_count = {}\n",
    "    for i in sym_list:\n",
    "        labels_count[i] = 0\n",
    "    for i in range(len(lst_data)):\n",
    "        j = one_hot_encode_to_char(lst_data[i])[0]\n",
    "        labels_count[j] += 1\n",
    "    return labels_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN without Batch Normalization\n",
    "def get_layers(input_shape, data_format, classes):\n",
    "    return [\n",
    "        Conv2D(25, (5, 5), padding='same', data_format=data_format, input_shape=input_shape),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Conv2D(50, (3, 3), padding='same', data_format=data_format),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "                \n",
    "        Conv2D(100, (2,2), padding='same', data_format=data_format),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Conv2D(200, (2,2), padding='same', data_format=data_format),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(3200),\n",
    "        Activation('relu'),\n",
    "        \n",
    "        Dense(1600),\n",
    "        Activation('relu'),\n",
    "        \n",
    "        Dense(classes),\n",
    "        Activation('softmax'),\n",
    "    ]\n",
    "\n",
    "def create_network_1(input_shape, data_format, classes):\n",
    "    model = Sequential()\n",
    "    layers = get_layers(input_shape, data_format, classes)\n",
    "    for i in layers:\n",
    "        model.add(i)\n",
    "    return model                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN with Batch Normalization\n",
    "def get_layers_bn(input_shape, data_format, classes):\n",
    "    return [\n",
    "        Conv2D(25, (5, 5), padding='same', data_format=data_format, input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Conv2D(50, (3, 3), padding='same', data_format=data_format),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "                \n",
    "        Conv2D(100, (2,2), padding='same', data_format=data_format),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Conv2D(200, (2,2), padding='same', data_format=data_format),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(3200),\n",
    "        Activation('relu'),\n",
    "        \n",
    "        Dense(1600),\n",
    "        Activation('relu'),\n",
    "        \n",
    "        Dense(classes),\n",
    "        Activation('softmax'),\n",
    "    ]\n",
    "\n",
    "def create_network_2(input_shape, data_format, classes):\n",
    "    model = Sequential()\n",
    "    layers = get_layers_bn(input_shape, data_format, classes)\n",
    "    for i in layers:\n",
    "        model.add(i)\n",
    "    return model                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(test_x, test_y, models, sym2latex_dict):\n",
    "    if len(models) < 0:\n",
    "        raise ValueError(\"No models found in models variable\")\n",
    "    if len(test_x) != len(test_y):\n",
    "        raise ValueError(\"Varibales test_x and test_y are of different length\")\n",
    "    \n",
    "    # convert test values from one hot encoded to label value\n",
    "    y_true = []\n",
    "    for i in range(len(test_y)):\n",
    "        # print(one_hot_encode_to_char(res[i], threshold = 0.5, get_max=False))\n",
    "        val = one_hot_encode_to_char(test_y[i], threshold = 0.9, get_max=True)\n",
    "        if len(val) > 0:\n",
    "            y_true.append(val[0])\n",
    "        else:\n",
    "            y_true.append(None)\n",
    "            print(\":(\")\n",
    "    no_models = len(models)\n",
    "    cols = ['symbol','latex']\n",
    "    preds = []\n",
    "    # convert predictions from one hot encoded to label value\n",
    "    for i in range(no_models):\n",
    "        print(\"Predictng labels for Model \"+str(i))\n",
    "        cols.append('model'+str(i))\n",
    "        \n",
    "        res = models[i].predict(X_test)\n",
    "        y_pred = []\n",
    "        for j in range(len(res)):\n",
    "            # print(one_hot_encode_to_char(res[i], threshold = 0.5, get_max=False))\n",
    "            val = one_hot_encode_to_char(res[j], threshold = 0.05, get_max=True)\n",
    "            if len(val) > 0:\n",
    "                y_pred.append(val[0])\n",
    "            else:\n",
    "                y_pred.append(None)\n",
    "                print(\":(\")\n",
    "        preds.append(y_pred)\n",
    "    print(\"Predictions Done\")\n",
    "    print(\"Comparing Results...\")\n",
    "    \n",
    "    # perform t test\n",
    "    t_test_result = pd.DataFrame(columns=cols)\n",
    "    for i in range(len(y_true)):\n",
    "        t_test_result.loc[i,'symbol'] = y_true[i]\n",
    "        t_test_result.loc[i,'latex'] = sym2latex_dict[y_true[i]]\n",
    "        for j in range(no_models):\n",
    "            t_test_result.loc[i, 'model'+str(j)] = sym2latex_dict[preds[j][i]]\n",
    "    print(\"Done\")    \n",
    "    return t_test_result\n",
    "\n",
    "def create_t_test_report(test_res):\n",
    "    models_names = list(test_res.columns.values[2:])\n",
    "    res = pd.DataFrame(columns=['latex','total_count']+models_names)\n",
    "    for i in range(len(symbols)):\n",
    "        res.loc[i,'latex'] = symbols.loc[i,'latex']\n",
    "        res.loc[i,'total_count'] = 0\n",
    "        for j in models_names:\n",
    "            res.loc[i,j] = 0\n",
    "    for i in range(len(test_res)):\n",
    "        res.loc[test_res.loc[i,'symbol'],'total_count'] += 1\n",
    "        for j in models_names:\n",
    "            if test_res.loc[i,'latex'] == test_res.loc[i,j]:\n",
    "                res.loc[latex2sym[test_res.loc[i,j]],j] += 1\n",
    "    for i in range(len(res)):\n",
    "        for j in models_names:\n",
    "            res.loc[i,j+'_acc'] = (res.loc[i,j]/res.loc[i,'total_count']) * 100\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T21:05:55.239469Z",
     "start_time": "2019-11-19T21:05:55.235454Z"
    }
   },
   "source": [
    "---\n",
    "# LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:37:47.718225Z",
     "start_time": "2019-11-26T22:37:47.558655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     path  symbol_id latex  user_id\n",
      "0  hasy-data/v2-00000.png         31     A       50\n",
      "1  hasy-data/v2-00001.png         31     A       10\n",
      "2  hasy-data/v2-00002.png         31     A       43\n",
      "3  hasy-data/v2-00003.png         31     A       43\n",
      "4  hasy-data/v2-00004.png         31     A     4435\n",
      "-----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168233 entries, 0 to 168232\n",
      "Data columns (total 4 columns):\n",
      "path         168233 non-null object\n",
      "symbol_id    168233 non-null int64\n",
      "latex        168233 non-null object\n",
      "user_id      168233 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 5.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "whole_dataset = read_csv('hasy-data-labels.csv')\n",
    "print(whole_dataset.head())\n",
    "print('-----------------')\n",
    "print(whole_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:37:47.732219Z",
     "start_time": "2019-11-26T22:37:47.720246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol_id latex  training_samples  test_samples\n",
      "0         31     A               137            22\n",
      "1         32     B                53             8\n",
      "2         33     C               120            14\n",
      "3         34     D                50             8\n",
      "4         35     E                48             6\n",
      "-----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369 entries, 0 to 368\n",
      "Data columns (total 4 columns):\n",
      "symbol_id           369 non-null int64\n",
      "latex               369 non-null object\n",
      "training_samples    369 non-null int64\n",
      "test_samples        369 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 11.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read symbols for all classification classes\n",
    "symbols = read_csv('symbols.csv')\n",
    "print(symbols.head())\n",
    "print('-----------------')\n",
    "print(symbols.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reset Symbol names to start from 0 and end at 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:39:07.391740Z",
     "start_time": "2019-11-26T22:39:07.369144Z"
    }
   },
   "outputs": [],
   "source": [
    "# change name of previous symbol\n",
    "symbols['old_symbol'] = symbols['symbol_id']\n",
    "symbols = symbols.drop('symbol_id', axis=1)\n",
    "\n",
    "# add new id according to index of character\n",
    "symbols['new_id'] = symbols.index\n",
    "\n",
    "# make a symbols dict that references each symbol_id to the new symbol\n",
    "symbols_dict = {}\n",
    "for i in range(len(symbols)):\n",
    "    symbols_dict[symbols['old_symbol'][i]] = symbols['new_id'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:39:27.828991Z",
     "start_time": "2019-11-26T22:39:07.393702Z"
    }
   },
   "outputs": [],
   "source": [
    "whole_dataset['symbol_id'] = [symbols_dict[i] for i in whole_dataset['symbol_id']]\n",
    "symbols_list = np.array(whole_dataset['symbol_id']).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.to_csv(data_dir = \"symbols_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY ONCE for creating the splits, \n",
    "# then load the saved csv's for both train and test splits\n",
    "# train, test = get_df_split(whole_dataset, stratify_col='symbol_id', test_size=0.1)\n",
    "# train = train.reset_index(drop=True)\n",
    "# test = test.reset_index(drop=True)\n",
    "# train.to_csv(dir_+'train.csv')\n",
    "# test.to_csv(dir_+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to load csvs\n",
    "train = read_csv('train.csv').drop(['Unnamed: 0'], axis=1).reset_index(drop=True)\n",
    "test = read_csv('test.csv').drop(['Unnamed: 0'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>latex</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasy-data/v2-15966.png</td>\n",
       "      <td>331</td>\n",
       "      <td>\\mathds{R}</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasy-data/v2-152185.png</td>\n",
       "      <td>312</td>\n",
       "      <td>\\mathcal{O}</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasy-data/v2-71601.png</td>\n",
       "      <td>125</td>\n",
       "      <td>\\%</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasy-data/v2-50153.png</td>\n",
       "      <td>93</td>\n",
       "      <td>\\varphi</td>\n",
       "      <td>124916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasy-data/v2-32919.png</td>\n",
       "      <td>68</td>\n",
       "      <td>\\gamma</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path  symbol_id        latex  user_id\n",
       "0   hasy-data/v2-15966.png        331   \\mathds{R}    16925\n",
       "1  hasy-data/v2-152185.png        312  \\mathcal{O}    16925\n",
       "2   hasy-data/v2-71601.png        125           \\%    16925\n",
       "3   hasy-data/v2-50153.png         93      \\varphi   124916\n",
       "4   hasy-data/v2-32919.png         68       \\gamma    16925"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>latex</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasy-data/v2-91515.png</td>\n",
       "      <td>171</td>\n",
       "      <td>\\approx</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasy-data/v2-33217.png</td>\n",
       "      <td>68</td>\n",
       "      <td>\\gamma</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasy-data/v2-31253.png</td>\n",
       "      <td>67</td>\n",
       "      <td>\\Sigma</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasy-data/v2-113978.png</td>\n",
       "      <td>224</td>\n",
       "      <td>\\uparrow</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasy-data/v2-36827.png</td>\n",
       "      <td>72</td>\n",
       "      <td>\\zeta</td>\n",
       "      <td>16925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path  symbol_id     latex  user_id\n",
       "0   hasy-data/v2-91515.png        171   \\approx    16925\n",
       "1   hasy-data/v2-33217.png         68    \\gamma    16925\n",
       "2   hasy-data/v2-31253.png         67    \\Sigma    16925\n",
       "3  hasy-data/v2-113978.png        224  \\uparrow    16925\n",
       "4   hasy-data/v2-36827.png         72     \\zeta    16925"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (143, 16, 89.94), 1: (55, 6, 90.16), 2: (121, 13, 90.3), 3: (52, 6, 89.66), 4: (49, 5, 90.74), 5: (50, 6, 89.29), 6: (106, 12, 89.83), 7: (58, 6, 90.62), 8: (90, 10, 90.0), 9: (94, 10, 90.38), 10: (86, 10, 89.58), 11: (100, 11, 90.09), 12: (108, 12, 90.0), 13: (95, 10, 90.48), 14: (76, 8, 90.48), 15: (65, 7, 90.28), 16: (60, 7, 89.55), 17: (75, 8, 90.36), 18: (57, 6, 90.48), 19: (50, 6, 89.29), 20: (53, 6, 89.83), 21: (50, 6, 89.29), 22: (56, 6, 90.32), 23: (49, 5, 90.74), 24: (50, 6, 89.29), 25: (59, 6, 90.77), 26: (959, 107, 89.96), 27: (120, 13, 90.23), 28: (106, 12, 89.83), 29: (112, 12, 90.32), 30: (108, 12, 90.0), 31: (55, 6, 90.16), 32: (70, 8, 89.74), 33: (90, 10, 90.0), 34: (68, 7, 90.67), 35: (109, 12, 90.08), 36: (81, 9, 90.0), 37: (1380, 153, 90.02), 38: (2341, 260, 90.0), 39: (1018, 113, 90.01), 40: (3060, 340, 90.0), 41: (1011, 112, 90.03), 42: (77, 9, 89.53), 43: (51, 6, 89.47), 44: (60, 7, 89.55), 45: (52, 6, 89.66), 46: (57, 6, 90.48), 47: (59, 7, 89.39), 48: (50, 6, 89.29), 49: (52, 6, 89.66), 50: (53, 6, 89.83), 51: (48, 5, 90.57), 52: (52, 6, 89.66), 53: (50, 6, 89.29), 54: (51, 6, 89.47), 55: (55, 6, 90.16), 56: (56, 6, 90.32), 57: (50, 5, 90.91), 58: (62, 7, 89.86), 59: (55, 6, 90.16), 60: (53, 6, 89.83), 61: (51, 6, 89.47), 62: (57, 6, 90.48), 63: (50, 6, 89.29), 64: (59, 7, 89.39), 65: (52, 6, 89.66), 66: (54, 6, 90.0), 67: (1719, 191, 90.0), 68: (1026, 114, 90.0), 69: (559, 62, 90.02), 70: (1121, 125, 89.97), 71: (896, 100, 89.96), 72: (785, 87, 90.02), 73: (617, 69, 89.94), 74: (586, 65, 90.02), 75: (415, 46, 90.02), 76: (490, 54, 90.07), 77: (667, 74, 90.01), 78: (140, 16, 89.74), 79: (226, 25, 90.04), 80: (129, 14, 90.21), 81: (896, 100, 89.96), 82: (397, 44, 90.02), 83: (1032, 115, 89.97), 84: (352, 39, 90.03), 85: (2310, 257, 89.99), 86: (358, 40, 89.95), 87: (719, 80, 89.99), 88: (623, 69, 90.03), 89: (200, 22, 90.09), 90: (382, 42, 90.09), 91: (618, 69, 89.96), 92: (546, 61, 89.95), 93: (1370, 152, 90.01), 94: (836, 93, 89.99), 95: (506, 56, 90.04), 96: (403, 45, 89.96), 97: (568, 63, 90.02), 98: (741, 82, 90.04), 99: (2172, 241, 90.01), 100: (3163, 351, 90.01), 101: (679, 76, 89.93), 102: (949, 105, 90.04), 103: (779, 87, 89.95), 104: (103, 11, 90.35), 105: (91, 10, 90.1), 106: (695, 77, 90.03), 107: (370, 41, 90.02), 108: (1418, 158, 89.97), 109: (364, 40, 90.1), 110: (1259, 140, 89.99), 111: (1246, 139, 89.96), 112: (106, 12, 89.83), 113: (81, 9, 90.0), 114: (50, 6, 89.29), 115: (348, 39, 89.92), 116: (1022, 114, 89.96), 117: (217, 24, 90.04), 118: (124, 14, 89.86), 119: (289, 32, 90.03), 120: (310, 35, 89.86), 121: (227, 25, 90.08), 122: (135, 15, 90.0), 123: (1157, 129, 89.97), 124: (960, 107, 89.97), 125: (798, 89, 89.97), 126: (787, 88, 89.94), 127: (107, 12, 89.92), 128: (114, 13, 89.76), 129: (166, 18, 90.22), 130: (831, 92, 90.03), 131: (1203, 134, 89.98), 132: (1358, 151, 89.99), 133: (501, 56, 89.95), 134: (120, 13, 90.23), 135: (968, 108, 89.96), 136: (137, 15, 90.13), 137: (225, 25, 90.0), 138: (1375, 153, 89.99), 139: (301, 34, 89.85), 140: (315, 35, 90.0), 141: (463, 51, 90.08), 142: (166, 18, 90.22), 143: (988, 110, 89.98), 144: (104, 11, 90.43), 145: (133, 15, 89.86), 146: (775, 86, 90.01), 147: (437, 49, 89.92), 148: (238, 26, 90.15), 149: (1307, 145, 90.01), 150: (882, 98, 90.0), 151: (91, 10, 90.1), 152: (235, 26, 90.04), 153: (50, 6, 89.29), 154: (97, 11, 89.81), 155: (102, 11, 90.27), 156: (109, 12, 90.08), 157: (199, 22, 90.05), 158: (95, 10, 90.48), 159: (193, 21, 90.19), 160: (240, 27, 89.89), 161: (106, 12, 89.83), 162: (95, 10, 90.48), 163: (1001, 111, 90.02), 164: (150, 17, 89.82), 165: (1067, 119, 89.97), 166: (86, 9, 90.53), 167: (182, 20, 90.1), 168: (266, 30, 89.86), 169: (127, 14, 90.07), 170: (288, 32, 90.0), 171: (1837, 204, 90.0), 172: (2266, 252, 89.99), 173: (345, 38, 90.08), 174: (991, 110, 90.01), 175: (135, 15, 90.0), 176: (81, 9, 90.0), 177: (471, 52, 90.06), 178: (326, 36, 90.06), 179: (216, 24, 90.0), 180: (249, 28, 89.89), 181: (181, 20, 90.05), 182: (302, 34, 89.88), 183: (961, 107, 89.98), 184: (192, 21, 90.14), 185: (427, 47, 90.08), 186: (1807, 201, 89.99), 187: (162, 18, 90.0), 188: (323, 36, 89.97), 189: (792, 88, 90.0), 190: (127, 14, 90.07), 191: (89, 10, 89.9), 192: (100, 11, 90.09), 193: (686, 76, 90.03), 194: (193, 22, 89.77), 195: (85, 9, 90.43), 196: (165, 18, 90.16), 197: (119, 13, 90.15), 198: (122, 13, 90.37), 199: (408, 45, 90.07), 200: (313, 35, 89.94), 201: (130, 14, 90.28), 202: (259, 29, 89.93), 203: (179, 20, 89.95), 204: (215, 24, 89.96), 205: (88, 10, 89.8), 206: (1374, 153, 89.98), 207: (274, 30, 90.13), 208: (87, 10, 89.69), 209: (696, 77, 90.04), 210: (577, 64, 90.02), 211: (358, 40, 89.95), 212: (150, 17, 89.82), 213: (54, 6, 90.0), 214: (512, 57, 89.98), 215: (148, 16, 90.24), 216: (184, 20, 90.2), 217: (1583, 176, 89.99), 218: (600, 67, 89.96), 219: (216, 24, 90.0), 220: (128, 14, 90.14), 221: (163, 18, 90.06), 222: (188, 21, 89.95), 223: (243, 27, 90.0), 224: (204, 23, 89.87), 225: (126, 14, 90.0), 226: (219, 24, 90.12), 227: (1111, 124, 89.96), 228: (823, 92, 89.95), 229: (454, 51, 89.9), 230: (181, 20, 90.05), 231: (188, 21, 89.95), 232: (195, 22, 89.86), 233: (562, 62, 90.06), 234: (150, 17, 89.82), 235: (111, 12, 90.24), 236: (125, 14, 89.93), 237: (125, 14, 89.93), 238: (154, 17, 90.06), 239: (147, 16, 90.18), 240: (373, 42, 89.88), 241: (87, 10, 89.69), 242: (166, 19, 89.73), 243: (125, 14, 89.93), 244: (109, 12, 90.08), 245: (247, 28, 89.82), 246: (494, 55, 89.98), 247: (254, 28, 90.07), 248: (131, 15, 89.73), 249: (660, 73, 90.04), 250: (1925, 214, 90.0), 251: (440, 49, 89.98), 252: (302, 34, 89.88), 253: (813, 90, 90.03), 254: (467, 52, 89.98), 255: (2066, 230, 89.98), 256: (1175, 131, 89.97), 257: (320, 36, 89.89), 258: (1262, 140, 90.01), 259: (109, 12, 90.08), 260: (174, 19, 90.16), 261: (281, 31, 90.06), 262: (686, 76, 90.03), 263: (143, 16, 89.94), 264: (312, 35, 89.91), 265: (158, 17, 90.29), 266: (378, 42, 90.0), 267: (132, 15, 89.8), 268: (824, 92, 89.96), 269: (233, 26, 89.96), 270: (460, 51, 90.02), 271: (333, 37, 90.0), 272: (479, 53, 90.04), 273: (696, 77, 90.04), 274: (158, 17, 90.29), 275: (367, 41, 89.95), 276: (359, 40, 89.97), 277: (135, 15, 90.0), 278: (687, 76, 90.04), 279: (2623, 291, 90.01), 280: (132, 15, 89.8), 281: (216, 24, 90.0), 282: (100, 11, 90.09), 283: (213, 24, 89.87), 284: (234, 26, 90.0), 285: (855, 95, 90.0), 286: (1095, 122, 89.98), 287: (114, 13, 89.76), 288: (247, 27, 90.15), 289: (819, 91, 90.0), 290: (759, 84, 90.04), 291: (284, 32, 89.87), 292: (880, 98, 89.98), 293: (93, 10, 90.29), 294: (1961, 218, 90.0), 295: (175, 19, 90.21), 296: (362, 40, 90.05), 297: (140, 15, 90.32), 298: (415, 46, 90.02), 299: (101, 11, 90.18), 300: (214, 24, 89.92), 301: (323, 36, 89.97), 302: (144, 16, 90.0), 303: (166, 18, 90.22), 304: (184, 20, 90.2), 305: (254, 28, 90.07), 306: (354, 39, 90.08), 307: (103, 11, 90.35), 308: (218, 24, 90.08), 309: (669, 74, 90.04), 310: (199, 22, 90.05), 311: (297, 33, 90.0), 312: (780, 87, 89.97), 313: (326, 36, 90.06), 314: (144, 16, 90.0), 315: (165, 18, 90.16), 316: (166, 18, 90.22), 317: (103, 11, 90.35), 318: (112, 12, 90.32), 319: (140, 16, 89.74), 320: (139, 15, 90.26), 321: (99, 11, 90.0), 322: (201, 22, 90.13), 323: (104, 11, 90.43), 324: (853, 95, 89.98), 325: (280, 31, 90.03), 326: (375, 42, 89.93), 327: (183, 20, 90.15), 328: (914, 102, 89.96), 329: (178, 20, 89.9), 330: (200, 22, 90.09), 331: (2140, 238, 89.99), 332: (907, 101, 89.98), 333: (166, 19, 89.73), 334: (197, 22, 89.95), 335: (125, 14, 89.93), 336: (91, 10, 90.1), 337: (119, 13, 90.15), 338: (188, 21, 89.95), 339: (724, 80, 90.05), 340: (104, 11, 90.43), 341: (174, 19, 90.16), 342: (296, 33, 89.97), 343: (604, 67, 90.01), 344: (297, 33, 90.0), 345: (113, 13, 89.68), 346: (204, 23, 89.87), 347: (268, 30, 89.93), 348: (128, 14, 90.14), 349: (91, 10, 90.1), 350: (158, 18, 89.77), 351: (342, 38, 90.0), 352: (251, 28, 89.96), 353: (175, 20, 89.74), 354: (147, 16, 90.18), 355: (241, 27, 89.93), 356: (48, 5, 90.57), 357: (46, 5, 90.2), 358: (59, 7, 89.39), 359: (65, 7, 90.28), 360: (216, 24, 90.0), 361: (208, 23, 90.04), 362: (89, 10, 89.9), 363: (682, 76, 89.97), 364: (213, 24, 89.87), 365: (283, 31, 90.13), 366: (257, 29, 89.86), 367: (134, 15, 89.93), 368: (96, 11, 89.72)}\n"
     ]
    }
   ],
   "source": [
    "# (train_count, test_count, percentage of train count to total)\n",
    "labels_count = get_label_count_df(train, test, symbols_list)\n",
    "print(labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:39:28.062035Z",
     "start_time": "2019-11-26T22:39:27.828991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset 151409\n",
      "len of dataset 16824\n"
     ]
    }
   ],
   "source": [
    "no_categories = 369\n",
    "train_one_hot_symbols = convert_to_one_hot_encode(train['symbol_id'], no_categories)\n",
    "test_one_hot_symbols = convert_to_one_hot_encode(test['symbol_id'], no_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole_dataset['symbol_id_ohe'] = [list(one_hot_symbols[i]) for i in range(len(whole_dataset))]\n",
    "train['symbol_id_ohe'] = [list(train_one_hot_symbols[i]) for i in range(len(train))]\n",
    "test['symbol_id_ohe'] = [list(test_one_hot_symbols[i]) for i in range(len(test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train = populate_images(train)\n",
    "test = populate_images(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>latex</th>\n",
       "      <th>user_id</th>\n",
       "      <th>symbol_id_ohe</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasy-data/v2-15966.png</td>\n",
       "      <td>331</td>\n",
       "      <td>\\mathds{R}</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 255, 255, 255, 255, 255, 255, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasy-data/v2-152185.png</td>\n",
       "      <td>312</td>\n",
       "      <td>\\mathcal{O}</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasy-data/v2-71601.png</td>\n",
       "      <td>125</td>\n",
       "      <td>\\%</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasy-data/v2-50153.png</td>\n",
       "      <td>93</td>\n",
       "      <td>\\varphi</td>\n",
       "      <td>124916</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasy-data/v2-32919.png</td>\n",
       "      <td>68</td>\n",
       "      <td>\\gamma</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path  symbol_id        latex  user_id  \\\n",
       "0   hasy-data/v2-15966.png        331   \\mathds{R}    16925   \n",
       "1  hasy-data/v2-152185.png        312  \\mathcal{O}    16925   \n",
       "2   hasy-data/v2-71601.png        125           \\%    16925   \n",
       "3   hasy-data/v2-50153.png         93      \\varphi   124916   \n",
       "4   hasy-data/v2-32919.png         68       \\gamma    16925   \n",
       "\n",
       "                                       symbol_id_ohe  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \n",
       "0  [[0, 0, 0, 0, 255, 255, 255, 255, 255, 255, 25...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 0, ...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>latex</th>\n",
       "      <th>user_id</th>\n",
       "      <th>symbol_id_ohe</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasy-data/v2-91515.png</td>\n",
       "      <td>171</td>\n",
       "      <td>\\approx</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasy-data/v2-33217.png</td>\n",
       "      <td>68</td>\n",
       "      <td>\\gamma</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 255, 255, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasy-data/v2-31253.png</td>\n",
       "      <td>67</td>\n",
       "      <td>\\Sigma</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 255, 255, 255, 255, 255, 255, 255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasy-data/v2-113978.png</td>\n",
       "      <td>224</td>\n",
       "      <td>\\uparrow</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasy-data/v2-36827.png</td>\n",
       "      <td>72</td>\n",
       "      <td>\\zeta</td>\n",
       "      <td>16925</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path  symbol_id     latex  user_id  \\\n",
       "0   hasy-data/v2-91515.png        171   \\approx    16925   \n",
       "1   hasy-data/v2-33217.png         68    \\gamma    16925   \n",
       "2   hasy-data/v2-31253.png         67    \\Sigma    16925   \n",
       "3  hasy-data/v2-113978.png        224  \\uparrow    16925   \n",
       "4   hasy-data/v2-36827.png         72     \\zeta    16925   \n",
       "\n",
       "                                       symbol_id_ohe  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 img  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 255, 255, 0, 0, 0, 0, 0, 0, 0...  \n",
       "2  [[0, 0, 0, 255, 255, 255, 255, 255, 255, 255, ...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# CONVOLUTIONAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:39:32.322770Z",
     "start_time": "2019-11-26T22:39:32.279853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Input Shape is (1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "smooth = 1\n",
    "\n",
    "# define the channels location\n",
    "data_format = 'channels_first'\n",
    "\n",
    "# number of classification labels/classes\n",
    "classes = 369\n",
    "\n",
    "# input shape of dataset\n",
    "input_shape = (1, 32, 32)\n",
    "print(\"CNN Input Shape is\", input_shape)\n",
    "\n",
    "# optimizer\n",
    "lr = 0.001\n",
    "optimizer = SGD(lr=lr)\n",
    "\n",
    "# loss function\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Stratified Train Test Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old method\n",
    "# X_train, X_test, y_train, y_test = gen_x_y_train_test_stratified_1df(whole_dataset, input_shape, test_size=0.2)\n",
    "# train_labels_count = get_label_count_list(y_train, symbols_list)\n",
    "# test_labels_count = get_label_count_list(y_test, symbols_list)\n",
    "# -----------------------------------\n",
    "# new \n",
    "X_train, X_test, y_train, y_test = process_x_y_train_test_stratified_2df(train, test, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "model = create_network_2(input_shape, data_format, classes)\n",
    "# compile network\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 32, 32)        650       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 16, 16)        11300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 8, 8)         20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100, 8, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 100, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 200, 4, 4)         80200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200, 4, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 200, 2, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3200)              2563200   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1600)              5121600   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 369)               590769    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 369)               0         \n",
      "=================================================================\n",
      "Total params: 8,388,059\n",
      "Trainable params: 8,387,939\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file=dir_+'model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151409 samples, validate on 16824 samples\n",
      "Epoch 1/300\n",
      "151409/151409 [==============================] - 31s 204us/step - loss: 5.5744 - acc: 0.0363 - val_loss: 5.3306 - val_acc: 0.0701\n",
      "Epoch 2/300\n",
      "151409/151409 [==============================] - 26s 172us/step - loss: 5.1936 - acc: 0.0835 - val_loss: 5.0596 - val_acc: 0.0942\n",
      "Epoch 3/300\n",
      "151409/151409 [==============================] - 26s 172us/step - loss: 4.9354 - acc: 0.1132 - val_loss: 4.8104 - val_acc: 0.1267\n",
      "Epoch 4/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 4.6738 - acc: 0.1569 - val_loss: 4.5473 - val_acc: 0.1839\n",
      "Epoch 5/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 4.3923 - acc: 0.2093 - val_loss: 4.2558 - val_acc: 0.2411\n",
      "Epoch 6/300\n",
      "151409/151409 [==============================] - 26s 173us/step - loss: 4.0871 - acc: 0.2665 - val_loss: 3.9388 - val_acc: 0.2908\n",
      "Epoch 7/300\n",
      "151409/151409 [==============================] - 26s 173us/step - loss: 3.7665 - acc: 0.3199 - val_loss: 3.6132 - val_acc: 0.3472\n",
      "Epoch 8/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 3.4472 - acc: 0.3751 - val_loss: 3.2995 - val_acc: 0.3996\n",
      "Epoch 9/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 3.1451 - acc: 0.4243 - val_loss: 3.0093 - val_acc: 0.4447\n",
      "Epoch 10/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 2.8714 - acc: 0.4643 - val_loss: 2.7502 - val_acc: 0.4796\n",
      "Epoch 11/300\n",
      "151409/151409 [==============================] - 26s 173us/step - loss: 2.6299 - acc: 0.4963 - val_loss: 2.5252 - val_acc: 0.5115\n",
      "Epoch 12/300\n",
      "151409/151409 [==============================] - 26s 173us/step - loss: 2.4198 - acc: 0.5225 - val_loss: 2.3335 - val_acc: 0.5323\n",
      "Epoch 13/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 2.2373 - acc: 0.5468 - val_loss: 2.1625 - val_acc: 0.5583\n",
      "Epoch 14/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 2.0779 - acc: 0.5696 - val_loss: 2.0151 - val_acc: 0.5792\n",
      "Epoch 15/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 1.9387 - acc: 0.5908 - val_loss: 1.8873 - val_acc: 0.5962\n",
      "Epoch 16/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 1.8166 - acc: 0.6090 - val_loss: 1.7744 - val_acc: 0.6160\n",
      "Epoch 17/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.7086 - acc: 0.6247 - val_loss: 1.6745 - val_acc: 0.6306\n",
      "Epoch 18/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 1.6132 - acc: 0.6401 - val_loss: 1.5861 - val_acc: 0.6458\n",
      "Epoch 19/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.5285 - acc: 0.6536 - val_loss: 1.5095 - val_acc: 0.6555\n",
      "Epoch 20/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 1.4528 - acc: 0.6669 - val_loss: 1.4373 - val_acc: 0.6688\n",
      "Epoch 21/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 1.3853 - acc: 0.6775 - val_loss: 1.3770 - val_acc: 0.6791\n",
      "Epoch 22/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 1.3250 - acc: 0.6887 - val_loss: 1.3205 - val_acc: 0.6860\n",
      "Epoch 23/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 1.2709 - acc: 0.6980 - val_loss: 1.2720 - val_acc: 0.6963\n",
      "Epoch 24/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 1.2220 - acc: 0.7066 - val_loss: 1.2269 - val_acc: 0.7022\n",
      "Epoch 25/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.1786 - acc: 0.7141 - val_loss: 1.1877 - val_acc: 0.7080\n",
      "Epoch 26/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 1.1388 - acc: 0.7213 - val_loss: 1.1494 - val_acc: 0.7202\n",
      "Epoch 27/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 1.1025 - acc: 0.7276 - val_loss: 1.1183 - val_acc: 0.7235\n",
      "Epoch 28/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.0703 - acc: 0.7328 - val_loss: 1.0873 - val_acc: 0.7282\n",
      "Epoch 29/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.0404 - acc: 0.7386 - val_loss: 1.0634 - val_acc: 0.7316\n",
      "Epoch 30/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 1.0128 - acc: 0.7438 - val_loss: 1.0391 - val_acc: 0.7354\n",
      "Epoch 31/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.9879 - acc: 0.7485 - val_loss: 1.0161 - val_acc: 0.7400\n",
      "Epoch 32/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.9653 - acc: 0.7526 - val_loss: 0.9950 - val_acc: 0.7433\n",
      "Epoch 33/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.9440 - acc: 0.7563 - val_loss: 0.9758 - val_acc: 0.7488\n",
      "Epoch 34/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.9243 - acc: 0.7603 - val_loss: 0.9586 - val_acc: 0.7519\n",
      "Epoch 35/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.9064 - acc: 0.7633 - val_loss: 0.9425 - val_acc: 0.7539\n",
      "Epoch 36/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.8893 - acc: 0.7669 - val_loss: 0.9278 - val_acc: 0.7564\n",
      "Epoch 37/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.8739 - acc: 0.7694 - val_loss: 0.9129 - val_acc: 0.7579\n",
      "Epoch 38/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.8586 - acc: 0.7722 - val_loss: 0.9051 - val_acc: 0.7596\n",
      "Epoch 39/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.8454 - acc: 0.7757 - val_loss: 0.8911 - val_acc: 0.7652\n",
      "Epoch 40/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.8323 - acc: 0.7772 - val_loss: 0.8775 - val_acc: 0.7688\n",
      "Epoch 41/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.8208 - acc: 0.7796 - val_loss: 0.8689 - val_acc: 0.7664\n",
      "Epoch 42/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.8088 - acc: 0.7824 - val_loss: 0.8575 - val_acc: 0.7710\n",
      "Epoch 43/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.7981 - acc: 0.7849 - val_loss: 0.8520 - val_acc: 0.7718\n",
      "Epoch 44/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7881 - acc: 0.7874 - val_loss: 0.8425 - val_acc: 0.7729\n",
      "Epoch 45/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7787 - acc: 0.7885 - val_loss: 0.8314 - val_acc: 0.7753\n",
      "Epoch 46/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7696 - acc: 0.7908 - val_loss: 0.8260 - val_acc: 0.7764\n",
      "Epoch 47/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7604 - acc: 0.7929 - val_loss: 0.8205 - val_acc: 0.7795\n",
      "Epoch 48/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.7525 - acc: 0.7950 - val_loss: 0.8134 - val_acc: 0.7817\n",
      "Epoch 49/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7446 - acc: 0.7956 - val_loss: 0.8076 - val_acc: 0.7818\n",
      "Epoch 50/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.7373 - acc: 0.7971 - val_loss: 0.7990 - val_acc: 0.7817\n",
      "Epoch 51/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.7296 - acc: 0.7996 - val_loss: 0.7931 - val_acc: 0.7829\n",
      "Epoch 52/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.7229 - acc: 0.8004 - val_loss: 0.7892 - val_acc: 0.7826\n",
      "Epoch 53/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.7161 - acc: 0.8027 - val_loss: 0.7843 - val_acc: 0.7845\n",
      "Epoch 54/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.7097 - acc: 0.8047 - val_loss: 0.7790 - val_acc: 0.7866\n",
      "Epoch 55/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.7037 - acc: 0.8047 - val_loss: 0.7725 - val_acc: 0.7856\n",
      "Epoch 56/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.6976 - acc: 0.8074 - val_loss: 0.7674 - val_acc: 0.7883\n",
      "Epoch 57/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.6919 - acc: 0.8082 - val_loss: 0.7668 - val_acc: 0.7887\n",
      "Epoch 58/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.6869 - acc: 0.8088 - val_loss: 0.7593 - val_acc: 0.7880\n",
      "Epoch 59/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.6812 - acc: 0.8101 - val_loss: 0.7598 - val_acc: 0.7861\n",
      "Epoch 60/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.6762 - acc: 0.8111 - val_loss: 0.7536 - val_acc: 0.7914\n",
      "Epoch 61/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.6714 - acc: 0.8127 - val_loss: 0.7466 - val_acc: 0.7901\n",
      "Epoch 62/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.6661 - acc: 0.8134 - val_loss: 0.7463 - val_acc: 0.7912\n",
      "Epoch 63/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.6616 - acc: 0.8146 - val_loss: 0.7416 - val_acc: 0.7917\n",
      "Epoch 64/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.6572 - acc: 0.8150 - val_loss: 0.7397 - val_acc: 0.7904\n",
      "Epoch 65/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.6525 - acc: 0.8167 - val_loss: 0.7341 - val_acc: 0.7923\n",
      "Epoch 66/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.6484 - acc: 0.8175 - val_loss: 0.7362 - val_acc: 0.7885\n",
      "Epoch 67/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.6443 - acc: 0.8187 - val_loss: 0.7300 - val_acc: 0.7920\n",
      "Epoch 68/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.6404 - acc: 0.8197 - val_loss: 0.7258 - val_acc: 0.7947\n",
      "Epoch 69/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.6363 - acc: 0.8208 - val_loss: 0.7292 - val_acc: 0.7964\n",
      "Epoch 70/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.6326 - acc: 0.8209 - val_loss: 0.7223 - val_acc: 0.7942\n",
      "Epoch 71/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.6289 - acc: 0.8218 - val_loss: 0.7194 - val_acc: 0.7973\n",
      "Epoch 72/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.6254 - acc: 0.8229 - val_loss: 0.7178 - val_acc: 0.7976\n",
      "Epoch 73/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.6213 - acc: 0.8238 - val_loss: 0.7140 - val_acc: 0.7982\n",
      "Epoch 74/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.6179 - acc: 0.8248 - val_loss: 0.7120 - val_acc: 0.7986\n",
      "Epoch 75/300\n",
      "151409/151409 [==============================] - 29s 194us/step - loss: 0.6144 - acc: 0.8252 - val_loss: 0.7094 - val_acc: 0.7991\n",
      "Epoch 76/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.6112 - acc: 0.8257 - val_loss: 0.7079 - val_acc: 0.8001\n",
      "Epoch 77/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.6078 - acc: 0.8271 - val_loss: 0.7042 - val_acc: 0.8015\n",
      "Epoch 78/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.6045 - acc: 0.8271 - val_loss: 0.7040 - val_acc: 0.7980\n",
      "Epoch 79/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.6016 - acc: 0.8282 - val_loss: 0.6991 - val_acc: 0.7999\n",
      "Epoch 80/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.5984 - acc: 0.8288 - val_loss: 0.6985 - val_acc: 0.8002\n",
      "Epoch 81/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.5953 - acc: 0.8305 - val_loss: 0.6947 - val_acc: 0.8011\n",
      "Epoch 82/300\n",
      "151409/151409 [==============================] - 30s 196us/step - loss: 0.5924 - acc: 0.8307 - val_loss: 0.6957 - val_acc: 0.8011\n",
      "Epoch 83/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5892 - acc: 0.8316 - val_loss: 0.6944 - val_acc: 0.8030\n",
      "Epoch 84/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.5864 - acc: 0.8317 - val_loss: 0.6928 - val_acc: 0.8025\n",
      "Epoch 85/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5834 - acc: 0.8328 - val_loss: 0.6883 - val_acc: 0.8028\n",
      "Epoch 86/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5810 - acc: 0.8327 - val_loss: 0.6881 - val_acc: 0.8050\n",
      "Epoch 87/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5780 - acc: 0.8344 - val_loss: 0.6904 - val_acc: 0.7977\n",
      "Epoch 88/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5753 - acc: 0.8345 - val_loss: 0.6851 - val_acc: 0.8059\n",
      "Epoch 89/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.5729 - acc: 0.8352 - val_loss: 0.6842 - val_acc: 0.8039\n",
      "Epoch 90/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5703 - acc: 0.8356 - val_loss: 0.6838 - val_acc: 0.8056\n",
      "Epoch 91/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5675 - acc: 0.8374 - val_loss: 0.6815 - val_acc: 0.8037\n",
      "Epoch 92/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5653 - acc: 0.8372 - val_loss: 0.6785 - val_acc: 0.8056\n",
      "Epoch 93/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5623 - acc: 0.8382 - val_loss: 0.6800 - val_acc: 0.8056\n",
      "Epoch 94/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.5600 - acc: 0.8384 - val_loss: 0.6773 - val_acc: 0.8041\n",
      "Epoch 95/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.5576 - acc: 0.8388 - val_loss: 0.6753 - val_acc: 0.8069\n",
      "Epoch 96/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5551 - acc: 0.8397 - val_loss: 0.6738 - val_acc: 0.8043\n",
      "Epoch 97/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5530 - acc: 0.8392 - val_loss: 0.6753 - val_acc: 0.8059\n",
      "Epoch 98/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.5506 - acc: 0.8408 - val_loss: 0.6697 - val_acc: 0.8063\n",
      "Epoch 99/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5482 - acc: 0.8417 - val_loss: 0.6721 - val_acc: 0.8018\n",
      "Epoch 100/300\n",
      "151409/151409 [==============================] - 29s 195us/step - loss: 0.5460 - acc: 0.8421 - val_loss: 0.6709 - val_acc: 0.8037\n",
      "Epoch 101/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.5437 - acc: 0.8419 - val_loss: 0.6683 - val_acc: 0.8055\n",
      "Epoch 102/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5412 - acc: 0.8434 - val_loss: 0.6722 - val_acc: 0.8020\n",
      "Epoch 103/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5393 - acc: 0.8440 - val_loss: 0.6694 - val_acc: 0.8024\n",
      "Epoch 104/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.5371 - acc: 0.8440 - val_loss: 0.6626 - val_acc: 0.8064\n",
      "Epoch 105/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5349 - acc: 0.8442 - val_loss: 0.6655 - val_acc: 0.8062\n",
      "Epoch 106/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5327 - acc: 0.8449 - val_loss: 0.6631 - val_acc: 0.8039\n",
      "Epoch 107/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5307 - acc: 0.8454 - val_loss: 0.6625 - val_acc: 0.8093\n",
      "Epoch 108/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.5281 - acc: 0.8466 - val_loss: 0.6621 - val_acc: 0.8081\n",
      "Epoch 109/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.5266 - acc: 0.8467 - val_loss: 0.6613 - val_acc: 0.8065\n",
      "Epoch 110/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5246 - acc: 0.8466 - val_loss: 0.6566 - val_acc: 0.8089\n",
      "Epoch 111/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.5223 - acc: 0.8476 - val_loss: 0.6583 - val_acc: 0.8077\n",
      "Epoch 112/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.5203 - acc: 0.8481 - val_loss: 0.6557 - val_acc: 0.8087\n",
      "Epoch 113/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.5186 - acc: 0.8492 - val_loss: 0.6533 - val_acc: 0.8122\n",
      "Epoch 114/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.5166 - acc: 0.8497 - val_loss: 0.6540 - val_acc: 0.8120\n",
      "Epoch 115/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.5147 - acc: 0.8502 - val_loss: 0.6564 - val_acc: 0.8091\n",
      "Epoch 116/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.5129 - acc: 0.8504 - val_loss: 0.6527 - val_acc: 0.8084\n",
      "Epoch 117/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5111 - acc: 0.8507 - val_loss: 0.6540 - val_acc: 0.8115\n",
      "Epoch 118/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.5088 - acc: 0.8514 - val_loss: 0.6529 - val_acc: 0.8077\n",
      "Epoch 119/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.5071 - acc: 0.8519 - val_loss: 0.6513 - val_acc: 0.8097\n",
      "Epoch 120/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.5053 - acc: 0.8519 - val_loss: 0.6504 - val_acc: 0.8116\n",
      "Epoch 121/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.5036 - acc: 0.8533 - val_loss: 0.6493 - val_acc: 0.8113\n",
      "Epoch 122/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.5015 - acc: 0.8530 - val_loss: 0.6506 - val_acc: 0.8125\n",
      "Epoch 123/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4996 - acc: 0.8542 - val_loss: 0.6506 - val_acc: 0.8064\n",
      "Epoch 124/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4981 - acc: 0.8545 - val_loss: 0.6487 - val_acc: 0.8104\n",
      "Epoch 125/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.4962 - acc: 0.8547 - val_loss: 0.6452 - val_acc: 0.8101\n",
      "Epoch 126/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4943 - acc: 0.8556 - val_loss: 0.6457 - val_acc: 0.8104\n",
      "Epoch 127/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.4927 - acc: 0.8553 - val_loss: 0.6437 - val_acc: 0.8093\n",
      "Epoch 128/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4909 - acc: 0.8562 - val_loss: 0.6453 - val_acc: 0.8147\n",
      "Epoch 129/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.4890 - acc: 0.8566 - val_loss: 0.6438 - val_acc: 0.8126\n",
      "Epoch 130/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.4873 - acc: 0.8574 - val_loss: 0.6423 - val_acc: 0.8131\n",
      "Epoch 131/300\n",
      "151409/151409 [==============================] - 29s 192us/step - loss: 0.4856 - acc: 0.8570 - val_loss: 0.6463 - val_acc: 0.8121\n",
      "Epoch 132/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4840 - acc: 0.8576 - val_loss: 0.6429 - val_acc: 0.8126\n",
      "Epoch 133/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.4823 - acc: 0.8579 - val_loss: 0.6417 - val_acc: 0.8106\n",
      "Epoch 134/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4806 - acc: 0.8590 - val_loss: 0.6417 - val_acc: 0.8108\n",
      "Epoch 135/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4788 - acc: 0.8598 - val_loss: 0.6397 - val_acc: 0.8129\n",
      "Epoch 136/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.4776 - acc: 0.8594 - val_loss: 0.6384 - val_acc: 0.8126\n",
      "Epoch 137/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4755 - acc: 0.8605 - val_loss: 0.6390 - val_acc: 0.8132\n",
      "Epoch 138/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4740 - acc: 0.8606 - val_loss: 0.6390 - val_acc: 0.8159\n",
      "Epoch 139/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4725 - acc: 0.8611 - val_loss: 0.6392 - val_acc: 0.8136\n",
      "Epoch 140/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4708 - acc: 0.8619 - val_loss: 0.6385 - val_acc: 0.8109\n",
      "Epoch 141/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.4692 - acc: 0.8620 - val_loss: 0.6381 - val_acc: 0.8100\n",
      "Epoch 142/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4682 - acc: 0.8626 - val_loss: 0.6372 - val_acc: 0.8126\n",
      "Epoch 143/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.4663 - acc: 0.8633 - val_loss: 0.6402 - val_acc: 0.8110\n",
      "Epoch 144/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.4651 - acc: 0.8632 - val_loss: 0.6366 - val_acc: 0.8102\n",
      "Epoch 145/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.4629 - acc: 0.8643 - val_loss: 0.6375 - val_acc: 0.8133\n",
      "Epoch 146/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4614 - acc: 0.8643 - val_loss: 0.6357 - val_acc: 0.8111\n",
      "Epoch 147/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.4595 - acc: 0.8651 - val_loss: 0.6359 - val_acc: 0.8120\n",
      "Epoch 148/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4583 - acc: 0.8653 - val_loss: 0.6383 - val_acc: 0.8134\n",
      "Epoch 149/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4569 - acc: 0.8653 - val_loss: 0.6371 - val_acc: 0.8127\n",
      "Epoch 150/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.4555 - acc: 0.8658 - val_loss: 0.6353 - val_acc: 0.8098\n",
      "Epoch 151/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4541 - acc: 0.8664 - val_loss: 0.6346 - val_acc: 0.8128\n",
      "Epoch 152/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.4526 - acc: 0.8667 - val_loss: 0.6346 - val_acc: 0.8090\n",
      "Epoch 153/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.4510 - acc: 0.8675 - val_loss: 0.6308 - val_acc: 0.8150\n",
      "Epoch 154/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4496 - acc: 0.8675 - val_loss: 0.6320 - val_acc: 0.8109\n",
      "Epoch 155/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.4476 - acc: 0.8683 - val_loss: 0.6353 - val_acc: 0.8116\n",
      "Epoch 156/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4463 - acc: 0.8689 - val_loss: 0.6337 - val_acc: 0.8110\n",
      "Epoch 157/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.4451 - acc: 0.8687 - val_loss: 0.6334 - val_acc: 0.8157\n",
      "Epoch 158/300\n",
      "151409/151409 [==============================] - 29s 188us/step - loss: 0.4438 - acc: 0.8691 - val_loss: 0.6324 - val_acc: 0.8128\n",
      "Epoch 159/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.4422 - acc: 0.8695 - val_loss: 0.6306 - val_acc: 0.8159\n",
      "Epoch 160/300\n",
      "151409/151409 [==============================] - 31s 203us/step - loss: 0.4404 - acc: 0.8700 - val_loss: 0.6326 - val_acc: 0.8102\n",
      "Epoch 161/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.4392 - acc: 0.8705 - val_loss: 0.6330 - val_acc: 0.8140\n",
      "Epoch 162/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.4379 - acc: 0.8710 - val_loss: 0.6276 - val_acc: 0.8145\n",
      "Epoch 163/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.4367 - acc: 0.8711 - val_loss: 0.6283 - val_acc: 0.8126\n",
      "Epoch 164/300\n",
      "151409/151409 [==============================] - 29s 192us/step - loss: 0.4350 - acc: 0.8719 - val_loss: 0.6309 - val_acc: 0.8138\n",
      "Epoch 165/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.4335 - acc: 0.8718 - val_loss: 0.6286 - val_acc: 0.8138\n",
      "Epoch 166/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.4322 - acc: 0.8726 - val_loss: 0.6291 - val_acc: 0.8153\n",
      "Epoch 167/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.4307 - acc: 0.8731 - val_loss: 0.6280 - val_acc: 0.8143\n",
      "Epoch 168/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.4295 - acc: 0.8732 - val_loss: 0.6298 - val_acc: 0.8147\n",
      "Epoch 169/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.4280 - acc: 0.8740 - val_loss: 0.6277 - val_acc: 0.8139\n",
      "Epoch 170/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4267 - acc: 0.8740 - val_loss: 0.6286 - val_acc: 0.8118\n",
      "Epoch 171/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.4254 - acc: 0.8744 - val_loss: 0.6292 - val_acc: 0.8143\n",
      "Epoch 172/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.4239 - acc: 0.8752 - val_loss: 0.6267 - val_acc: 0.8145\n",
      "Epoch 173/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.4224 - acc: 0.8757 - val_loss: 0.6283 - val_acc: 0.8160\n",
      "Epoch 174/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.4213 - acc: 0.8755 - val_loss: 0.6291 - val_acc: 0.8134\n",
      "Epoch 175/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.4200 - acc: 0.8761 - val_loss: 0.6269 - val_acc: 0.8163\n",
      "Epoch 176/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.4181 - acc: 0.8766 - val_loss: 0.6271 - val_acc: 0.8147\n",
      "Epoch 177/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.4174 - acc: 0.8772 - val_loss: 0.6253 - val_acc: 0.8121\n",
      "Epoch 178/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.4157 - acc: 0.8776 - val_loss: 0.6246 - val_acc: 0.8126\n",
      "Epoch 179/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4145 - acc: 0.8776 - val_loss: 0.6273 - val_acc: 0.8153\n",
      "Epoch 180/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4134 - acc: 0.8777 - val_loss: 0.6236 - val_acc: 0.8148\n",
      "Epoch 181/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.4121 - acc: 0.8787 - val_loss: 0.6267 - val_acc: 0.8153\n",
      "Epoch 182/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.4104 - acc: 0.8788 - val_loss: 0.6265 - val_acc: 0.8153\n",
      "Epoch 183/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.4093 - acc: 0.8791 - val_loss: 0.6232 - val_acc: 0.8151\n",
      "Epoch 184/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4081 - acc: 0.8799 - val_loss: 0.6249 - val_acc: 0.8167\n",
      "Epoch 185/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4066 - acc: 0.8800 - val_loss: 0.6226 - val_acc: 0.8162\n",
      "Epoch 186/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.4051 - acc: 0.8805 - val_loss: 0.6248 - val_acc: 0.8153\n",
      "Epoch 187/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.4042 - acc: 0.8805 - val_loss: 0.6255 - val_acc: 0.8163\n",
      "Epoch 188/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4025 - acc: 0.8814 - val_loss: 0.6257 - val_acc: 0.8145\n",
      "Epoch 189/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.4016 - acc: 0.8817 - val_loss: 0.6278 - val_acc: 0.8157\n",
      "Epoch 190/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.4001 - acc: 0.8821 - val_loss: 0.6243 - val_acc: 0.8136\n",
      "Epoch 191/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3990 - acc: 0.8822 - val_loss: 0.6224 - val_acc: 0.8128\n",
      "Epoch 192/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3974 - acc: 0.8829 - val_loss: 0.6264 - val_acc: 0.8135\n",
      "Epoch 193/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3963 - acc: 0.8835 - val_loss: 0.6270 - val_acc: 0.8159\n",
      "Epoch 194/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.3951 - acc: 0.8836 - val_loss: 0.6264 - val_acc: 0.8116\n",
      "Epoch 195/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.3937 - acc: 0.8836 - val_loss: 0.6236 - val_acc: 0.8144\n",
      "Epoch 196/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3928 - acc: 0.8842 - val_loss: 0.6248 - val_acc: 0.8161\n",
      "Epoch 197/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3914 - acc: 0.8846 - val_loss: 0.6263 - val_acc: 0.8108\n",
      "Epoch 198/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3898 - acc: 0.8853 - val_loss: 0.6257 - val_acc: 0.8148\n",
      "Epoch 199/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3887 - acc: 0.8856 - val_loss: 0.6234 - val_acc: 0.8160\n",
      "Epoch 200/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.3874 - acc: 0.8858 - val_loss: 0.6237 - val_acc: 0.8165\n",
      "Epoch 201/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3865 - acc: 0.8866 - val_loss: 0.6217 - val_acc: 0.8144\n",
      "Epoch 202/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3851 - acc: 0.8871 - val_loss: 0.6248 - val_acc: 0.8156\n",
      "Epoch 203/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3839 - acc: 0.8870 - val_loss: 0.6260 - val_acc: 0.8150\n",
      "Epoch 204/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3826 - acc: 0.8875 - val_loss: 0.6223 - val_acc: 0.8144\n",
      "Epoch 205/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3812 - acc: 0.8880 - val_loss: 0.6229 - val_acc: 0.8189\n",
      "Epoch 206/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3799 - acc: 0.8882 - val_loss: 0.6263 - val_acc: 0.8131\n",
      "Epoch 207/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3789 - acc: 0.8885 - val_loss: 0.6240 - val_acc: 0.8147\n",
      "Epoch 208/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.3780 - acc: 0.8889 - val_loss: 0.6257 - val_acc: 0.8107\n",
      "Epoch 209/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3765 - acc: 0.8887 - val_loss: 0.6331 - val_acc: 0.8097\n",
      "Epoch 210/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3753 - acc: 0.8893 - val_loss: 0.6238 - val_acc: 0.8155\n",
      "Epoch 211/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3741 - acc: 0.8899 - val_loss: 0.6248 - val_acc: 0.8153\n",
      "Epoch 212/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3727 - acc: 0.8903 - val_loss: 0.6285 - val_acc: 0.8135\n",
      "Epoch 213/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.3719 - acc: 0.8903 - val_loss: 0.6232 - val_acc: 0.8137\n",
      "Epoch 214/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3708 - acc: 0.8910 - val_loss: 0.6238 - val_acc: 0.8140\n",
      "Epoch 215/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3692 - acc: 0.8918 - val_loss: 0.6224 - val_acc: 0.8158\n",
      "Epoch 216/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3682 - acc: 0.8919 - val_loss: 0.6289 - val_acc: 0.8173\n",
      "Epoch 217/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3669 - acc: 0.8925 - val_loss: 0.6219 - val_acc: 0.8164\n",
      "Epoch 218/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3663 - acc: 0.8933 - val_loss: 0.6225 - val_acc: 0.8159\n",
      "Epoch 219/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3648 - acc: 0.8934 - val_loss: 0.6221 - val_acc: 0.8162\n",
      "Epoch 220/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3633 - acc: 0.8938 - val_loss: 0.6258 - val_acc: 0.8121\n",
      "Epoch 221/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3623 - acc: 0.8941 - val_loss: 0.6227 - val_acc: 0.8151\n",
      "Epoch 222/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3613 - acc: 0.8940 - val_loss: 0.6251 - val_acc: 0.8179\n",
      "Epoch 223/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3598 - acc: 0.8952 - val_loss: 0.6217 - val_acc: 0.8167\n",
      "Epoch 224/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3587 - acc: 0.8952 - val_loss: 0.6249 - val_acc: 0.8154\n",
      "Epoch 225/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3580 - acc: 0.8953 - val_loss: 0.6237 - val_acc: 0.8145\n",
      "Epoch 226/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3566 - acc: 0.8956 - val_loss: 0.6234 - val_acc: 0.8140\n",
      "Epoch 227/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.3551 - acc: 0.8964 - val_loss: 0.6261 - val_acc: 0.8098\n",
      "Epoch 228/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3540 - acc: 0.8958 - val_loss: 0.6235 - val_acc: 0.8167\n",
      "Epoch 229/300\n",
      "151409/151409 [==============================] - 27s 176us/step - loss: 0.3531 - acc: 0.8971 - val_loss: 0.6287 - val_acc: 0.8131\n",
      "Epoch 230/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3518 - acc: 0.8976 - val_loss: 0.6234 - val_acc: 0.8142\n",
      "Epoch 231/300\n",
      "151409/151409 [==============================] - 26s 174us/step - loss: 0.3506 - acc: 0.8975 - val_loss: 0.6221 - val_acc: 0.8135\n",
      "Epoch 232/300\n",
      "151409/151409 [==============================] - 27s 175us/step - loss: 0.3495 - acc: 0.8978 - val_loss: 0.6244 - val_acc: 0.8144\n",
      "Epoch 233/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3486 - acc: 0.8978 - val_loss: 0.6267 - val_acc: 0.8144\n",
      "Epoch 234/300\n",
      "151409/151409 [==============================] - 26s 175us/step - loss: 0.3472 - acc: 0.8987 - val_loss: 0.6275 - val_acc: 0.8149\n",
      "Epoch 235/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.3464 - acc: 0.8987 - val_loss: 0.6275 - val_acc: 0.8141\n",
      "Epoch 236/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3450 - acc: 0.8997 - val_loss: 0.6241 - val_acc: 0.8141\n",
      "Epoch 237/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3439 - acc: 0.8998 - val_loss: 0.6252 - val_acc: 0.8151\n",
      "Epoch 238/300\n",
      "151409/151409 [==============================] - 27s 178us/step - loss: 0.3431 - acc: 0.9000 - val_loss: 0.6279 - val_acc: 0.8165\n",
      "Epoch 239/300\n",
      "151409/151409 [==============================] - 27s 177us/step - loss: 0.3414 - acc: 0.8999 - val_loss: 0.6244 - val_acc: 0.8158\n",
      "Epoch 240/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3406 - acc: 0.9015 - val_loss: 0.6229 - val_acc: 0.8131\n",
      "Epoch 241/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.3396 - acc: 0.9008 - val_loss: 0.6285 - val_acc: 0.8150\n",
      "Epoch 242/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.3381 - acc: 0.9017 - val_loss: 0.6258 - val_acc: 0.8144\n",
      "Epoch 243/300\n",
      "151409/151409 [==============================] - 27s 179us/step - loss: 0.3374 - acc: 0.9020 - val_loss: 0.6264 - val_acc: 0.8113\n",
      "Epoch 244/300\n",
      "151409/151409 [==============================] - 29s 192us/step - loss: 0.3362 - acc: 0.9024 - val_loss: 0.6301 - val_acc: 0.8173\n",
      "Epoch 245/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.3349 - acc: 0.9029 - val_loss: 0.6294 - val_acc: 0.8143\n",
      "Epoch 246/300\n",
      "151409/151409 [==============================] - 28s 182us/step - loss: 0.3337 - acc: 0.9030 - val_loss: 0.6263 - val_acc: 0.8136\n",
      "Epoch 247/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.3329 - acc: 0.9026 - val_loss: 0.6320 - val_acc: 0.8106\n",
      "Epoch 248/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.3314 - acc: 0.9040 - val_loss: 0.6309 - val_acc: 0.8157\n",
      "Epoch 249/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.3304 - acc: 0.9045 - val_loss: 0.6254 - val_acc: 0.8163\n",
      "Epoch 250/300\n",
      "151409/151409 [==============================] - 30s 196us/step - loss: 0.3296 - acc: 0.9040 - val_loss: 0.6278 - val_acc: 0.8121\n",
      "Epoch 251/300\n",
      "151409/151409 [==============================] - 30s 195us/step - loss: 0.3284 - acc: 0.9049 - val_loss: 0.6284 - val_acc: 0.8106\n",
      "Epoch 252/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.3272 - acc: 0.9050 - val_loss: 0.6271 - val_acc: 0.8147\n",
      "Epoch 253/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.3261 - acc: 0.9057 - val_loss: 0.6280 - val_acc: 0.8121\n",
      "Epoch 254/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.3250 - acc: 0.9058 - val_loss: 0.6255 - val_acc: 0.8158\n",
      "Epoch 255/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.3244 - acc: 0.9060 - val_loss: 0.6298 - val_acc: 0.8147\n",
      "Epoch 256/300\n",
      "151409/151409 [==============================] - 27s 180us/step - loss: 0.3233 - acc: 0.9064 - val_loss: 0.6286 - val_acc: 0.8158\n",
      "Epoch 257/300\n",
      "151409/151409 [==============================] - 28s 182us/step - loss: 0.3213 - acc: 0.9069 - val_loss: 0.6255 - val_acc: 0.8172\n",
      "Epoch 258/300\n",
      "151409/151409 [==============================] - 28s 182us/step - loss: 0.3207 - acc: 0.9075 - val_loss: 0.6291 - val_acc: 0.8150\n",
      "Epoch 259/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.3196 - acc: 0.9072 - val_loss: 0.6331 - val_acc: 0.8138\n",
      "Epoch 260/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.3185 - acc: 0.9078 - val_loss: 0.6345 - val_acc: 0.8113\n",
      "Epoch 261/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.3177 - acc: 0.9087 - val_loss: 0.6297 - val_acc: 0.8156\n",
      "Epoch 262/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.3163 - acc: 0.9089 - val_loss: 0.6285 - val_acc: 0.8133\n",
      "Epoch 263/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.3152 - acc: 0.9090 - val_loss: 0.6333 - val_acc: 0.8144 - acc\n",
      "Epoch 264/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.3143 - acc: 0.9094 - val_loss: 0.6397 - val_acc: 0.8159\n",
      "Epoch 265/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.3132 - acc: 0.9099 - val_loss: 0.6322 - val_acc: 0.8168\n",
      "Epoch 266/300\n",
      "151409/151409 [==============================] - 28s 183us/step - loss: 0.3124 - acc: 0.9097 - val_loss: 0.6303 - val_acc: 0.8135\n",
      "Epoch 267/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.3114 - acc: 0.9103 - val_loss: 0.6364 - val_acc: 0.8119\n",
      "Epoch 268/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.3104 - acc: 0.9109 - val_loss: 0.6325 - val_acc: 0.8116\n",
      "Epoch 269/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.3088 - acc: 0.9112 - val_loss: 0.6323 - val_acc: 0.8145\n",
      "Epoch 270/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.3081 - acc: 0.9114 - val_loss: 0.6319 - val_acc: 0.8162\n",
      "Epoch 271/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.3071 - acc: 0.9117 - val_loss: 0.6305 - val_acc: 0.8135 loss: 0.3072 - acc: 0.911\n",
      "Epoch 272/300\n",
      "151409/151409 [==============================] - 28s 185us/step - loss: 0.3058 - acc: 0.9123 - val_loss: 0.6353 - val_acc: 0.8111s: 0.3053 - acc:  - ET\n",
      "Epoch 273/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.3051 - acc: 0.9124 - val_loss: 0.6293 - val_acc: 0.8146 - loss: 0.3047 - ac\n",
      "Epoch 274/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.3039 - acc: 0.9124 - val_loss: 0.6323 - val_acc: 0.8147\n",
      "Epoch 275/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.3028 - acc: 0.9129 - val_loss: 0.6335 - val_acc: 0.8147\n",
      "Epoch 276/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.3015 - acc: 0.9138 - val_loss: 0.6382 - val_acc: 0.8156\n",
      "Epoch 277/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.3009 - acc: 0.9140 - val_loss: 0.6324 - val_acc: 0.8128\n",
      "Epoch 278/300\n",
      "151409/151409 [==============================] - 28s 182us/step - loss: 0.2999 - acc: 0.9140 - val_loss: 0.6334 - val_acc: 0.8151\n",
      "Epoch 279/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.2984 - acc: 0.9146 - val_loss: 0.6362 - val_acc: 0.8109\n",
      "Epoch 280/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.2976 - acc: 0.9147 - val_loss: 0.6370 - val_acc: 0.8124- acc: 0.914\n",
      "Epoch 281/300\n",
      "151409/151409 [==============================] - 29s 189us/step - loss: 0.2970 - acc: 0.9143 - val_loss: 0.6335 - val_acc: 0.8122\n",
      "Epoch 282/300\n",
      "151409/151409 [==============================] - 27s 181us/step - loss: 0.2956 - acc: 0.9159 - val_loss: 0.6335 - val_acc: 0.8131\n",
      "Epoch 283/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.2943 - acc: 0.9158 - val_loss: 0.6358 - val_acc: 0.8125\n",
      "Epoch 284/300\n",
      "151409/151409 [==============================] - 28s 183us/step - loss: 0.2937 - acc: 0.9165 - val_loss: 0.6358 - val_acc: 0.8131\n",
      "Epoch 285/300\n",
      "151409/151409 [==============================] - 28s 183us/step - loss: 0.2928 - acc: 0.9162 - val_loss: 0.6436 - val_acc: 0.8130\n",
      "Epoch 286/300\n",
      "151409/151409 [==============================] - 29s 191us/step - loss: 0.2915 - acc: 0.9166 - val_loss: 0.6328 - val_acc: 0.8159\n",
      "Epoch 287/300\n",
      "151409/151409 [==============================] - 28s 187us/step - loss: 0.2905 - acc: 0.9176 - val_loss: 0.6338 - val_acc: 0.8137\n",
      "Epoch 288/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.2894 - acc: 0.9181 - val_loss: 0.6348 - val_acc: 0.8141\n",
      "Epoch 289/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.2888 - acc: 0.9180 - val_loss: 0.6414 - val_acc: 0.8150\n",
      "Epoch 290/300\n",
      "151409/151409 [==============================] - 28s 184us/step - loss: 0.2872 - acc: 0.9186 - val_loss: 0.6377 - val_acc: 0.8121\n",
      "Epoch 291/300\n",
      "151409/151409 [==============================] - 28s 186us/step - loss: 0.2864 - acc: 0.9184 - val_loss: 0.6380 - val_acc: 0.8106\n",
      "Epoch 292/300\n",
      "151409/151409 [==============================] - 28s 182us/step - loss: 0.2852 - acc: 0.9192 - val_loss: 0.6355 - val_acc: 0.8132\n",
      "Epoch 293/300\n",
      "151409/151409 [==============================] - 28s 188us/step - loss: 0.2844 - acc: 0.9197 - val_loss: 0.6382 - val_acc: 0.8119\n",
      "Epoch 294/300\n",
      "151409/151409 [==============================] - 29s 193us/step - loss: 0.2835 - acc: 0.9196 - val_loss: 0.6387 - val_acc: 0.8102\n",
      "Epoch 295/300\n",
      "151409/151409 [==============================] - 29s 190us/step - loss: 0.2826 - acc: 0.9197 - val_loss: 0.6473 - val_acc: 0.8076\n",
      "Epoch 296/300\n",
      "151409/151409 [==============================] - 29s 192us/step - loss: 0.2812 - acc: 0.9209 - val_loss: 0.6405 - val_acc: 0.8122 - loss: 0.2819 - acc:  - ETA: 0s - loss: 0.2809 - acc: 0.\n",
      "Epoch 297/300\n",
      "151409/151409 [==============================] - 29s 195us/step - loss: 0.2804 - acc: 0.9202 - val_loss: 0.6379 - val_acc: 0.8127\n",
      "Epoch 298/300\n",
      "151409/151409 [==============================] - 29s 194us/step - loss: 0.2795 - acc: 0.9207 - val_loss: 0.6382 - val_acc: 0.8156\n",
      "Epoch 299/300\n",
      "151409/151409 [==============================] - 30s 199us/step - loss: 0.2781 - acc: 0.9213 - val_loss: 0.6386 - val_acc: 0.8125\n",
      "Epoch 300/300\n",
      "151409/151409 [==============================] - 30s 199us/step - loss: 0.2774 - acc: 0.9215 - val_loss: 0.6407 - val_acc: 0.8132\n",
      "Training completed on 02/16\n"
     ]
    }
   ],
   "source": [
    "# Fit dataset\n",
    "epochs = 300\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "model.save(model_dir+'hasyv2model41.h5')\n",
    "print(\"Training completed on 02/16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load model use\n",
    "model = load_model(model_dir+'hasyv2model41.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions from one hot encoded to label value\n",
    "y_pred = convert_pred_list_ohe_to_labels(res, threshold=0.05, get_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test values from one hot encoded to label value\n",
    "y_true = convert_pred_list_ohe_to_labels(y_test, threshold=0.9, get_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x299a30deb70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spectral Color Map used: Violet means 1, Red means -1 and Yellow means 0\n",
    "cfs10 = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(20,20))\n",
    "sn.heatmap(cfs10, cmap=\"Spectral\", robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6250    0.6452        16\n",
      "           1     0.7500    0.5000    0.6000         6\n",
      "           2     0.8750    0.5385    0.6667        13\n",
      "           3     0.5000    0.5000    0.5000         6\n",
      "           4     0.8333    1.0000    0.9091         5\n",
      "           5     0.8000    0.6667    0.7273         6\n",
      "           6     1.0000    0.9167    0.9565        12\n",
      "           7     0.8000    0.6667    0.7273         6\n",
      "           8     1.0000    0.4000    0.5714        10\n",
      "           9     1.0000    0.8000    0.8889        10\n",
      "          10     0.7500    0.9000    0.8182        10\n",
      "          11     0.6000    0.5455    0.5714        11\n",
      "          12     0.8333    0.8333    0.8333        12\n",
      "          13     0.8750    0.7000    0.7778        10\n",
      "          14     1.0000    0.2500    0.4000         8\n",
      "          15     0.6250    0.7143    0.6667         7\n",
      "          16     0.7500    0.4286    0.5455         7\n",
      "          17     0.6000    0.7500    0.6667         8\n",
      "          18     0.3333    0.1667    0.2222         6\n",
      "          19     0.0000    0.0000    0.0000         6\n",
      "          20     0.4000    0.3333    0.3636         6\n",
      "          21     1.0000    0.1667    0.2857         6\n",
      "          22     0.3333    0.3333    0.3333         6\n",
      "          23     0.6667    0.4000    0.5000         5\n",
      "          24     0.5000    0.3333    0.4000         6\n",
      "          25     0.5000    0.5000    0.5000         6\n",
      "          26     0.6735    0.9252    0.7795       107\n",
      "          27     0.5333    0.6154    0.5714        13\n",
      "          28     0.8182    0.7500    0.7826        12\n",
      "          29     0.8571    1.0000    0.9231        12\n",
      "          30     1.0000    0.6667    0.8000        12\n",
      "          31     1.0000    1.0000    1.0000         6\n",
      "          32     0.6667    0.5000    0.5714         8\n",
      "          33     1.0000    0.6000    0.7500        10\n",
      "          34     1.0000    0.8571    0.9231         7\n",
      "          35     0.7778    0.5833    0.6667        12\n",
      "          36     0.3333    0.2222    0.2667         9\n",
      "          37     0.7945    0.7582    0.7759       153\n",
      "          38     0.8039    0.7885    0.7961       260\n",
      "          39     0.7698    0.8584    0.8117       113\n",
      "          40     0.6442    0.8147    0.7195       340\n",
      "          41     0.8475    0.8929    0.8696       112\n",
      "          42     0.5556    0.5556    0.5556         9\n",
      "          43     0.7143    0.8333    0.7692         6\n",
      "          44     0.5000    0.2857    0.3636         7\n",
      "          45     0.8571    1.0000    0.9231         6\n",
      "          46     0.4286    0.5000    0.4615         6\n",
      "          47     0.5000    0.7143    0.5882         7\n",
      "          48     0.6667    0.3333    0.4444         6\n",
      "          49     0.8571    1.0000    0.9231         6\n",
      "          50     1.0000    1.0000    1.0000         6\n",
      "          51     1.0000    0.8000    0.8889         5\n",
      "          52     0.7143    0.8333    0.7692         6\n",
      "          53     0.5000    0.1667    0.2500         6\n",
      "          54     1.0000    0.3333    0.5000         6\n",
      "          55     0.6000    0.5000    0.5455         6\n",
      "          56     0.0000    0.0000    0.0000         6\n",
      "          57     0.5000    0.8000    0.6154         5\n",
      "          58     0.5556    0.7143    0.6250         7\n",
      "          59     0.6667    0.6667    0.6667         6\n",
      "          60     0.5000    0.8333    0.6250         6\n",
      "          61     1.0000    0.3333    0.5000         6\n",
      "          62     1.0000    0.1667    0.2857         6\n",
      "          63     0.6667    0.3333    0.4444         6\n",
      "          64     0.0000    0.0000    0.0000         7\n",
      "          65     0.5000    0.5000    0.5000         6\n",
      "          66     0.0000    0.0000    0.0000         6\n",
      "          67     0.3784    0.2199    0.2781       191\n",
      "          68     0.8947    0.8947    0.8947       114\n",
      "          69     0.8209    0.8871    0.8527        62\n",
      "          70     0.9147    0.9440    0.9291       125\n",
      "          71     0.6923    0.8100    0.7465       100\n",
      "          72     0.8590    0.7701    0.8121        87\n",
      "          73     0.8701    0.9710    0.9178        69\n",
      "          74     0.8361    0.7846    0.8095        65\n",
      "          75     0.6250    0.7609    0.6863        46\n",
      "          76     0.1667    0.0926    0.1190        54\n",
      "          77     0.5778    0.7027    0.6341        74\n",
      "          78     0.8333    0.9375    0.8824        16\n",
      "          79     0.6818    0.6000    0.6383        25\n",
      "          80     0.5556    0.3571    0.4348        14\n",
      "          81     0.9490    0.9300    0.9394       100\n",
      "          82     0.5227    0.5227    0.5227        44\n",
      "          83     0.8730    0.9565    0.9129       115\n",
      "          84     0.7381    0.7949    0.7654        39\n",
      "          85     0.8881    0.9261    0.9067       257\n",
      "          86     0.9268    0.9500    0.9383        40\n",
      "          87     0.2391    0.1375    0.1746        80\n",
      "          88     0.8088    0.7971    0.8029        69\n",
      "          89     0.5833    0.6364    0.6087        22\n",
      "          90     0.8205    0.7619    0.7901        42\n",
      "          91     0.6429    0.6522    0.6475        69\n",
      "          92     0.8246    0.7705    0.7966        61\n",
      "          93     0.9172    0.9474    0.9320       152\n",
      "          94     0.8172    0.8172    0.8172        93\n",
      "          95     0.6897    0.7143    0.7018        56\n",
      "          96     0.6122    0.6667    0.6383        45\n",
      "          97     0.9104    0.9683    0.9385        63\n",
      "          98     0.7195    0.7195    0.7195        82\n",
      "          99     0.9669    0.9710    0.9689       241\n",
      "         100     0.9580    0.9744    0.9661       351\n",
      "         101     0.8068    0.9342    0.8659        76\n",
      "         102     0.8077    0.8000    0.8038       105\n",
      "         103     0.7938    0.8851    0.8370        87\n",
      "         104     0.6000    0.8182    0.6923        11\n",
      "         105     0.5385    0.7000    0.6087        10\n",
      "         106     0.8706    0.9610    0.9136        77\n",
      "         107     0.9762    1.0000    0.9880        41\n",
      "         108     0.9560    0.9620    0.9590       158\n",
      "         109     1.0000    0.9250    0.9610        40\n",
      "         110     0.9925    0.9500    0.9708       140\n",
      "         111     0.6099    0.6187    0.6143       139\n",
      "         112     0.8000    1.0000    0.8889        12\n",
      "         113     0.8889    0.8889    0.8889         9\n",
      "         114     0.0000    0.0000    0.0000         6\n",
      "         115     0.8293    0.8718    0.8500        39\n",
      "         116     0.9810    0.9035    0.9406       114\n",
      "         117     0.8148    0.9167    0.8627        24\n",
      "         118     0.7333    0.7857    0.7586        14\n",
      "         119     0.9630    0.8125    0.8814        32\n",
      "         120     0.7778    0.6000    0.6774        35\n",
      "         121     0.7742    0.9600    0.8571        25\n",
      "         122     0.8125    0.8667    0.8387        15\n",
      "         123     0.7746    0.8527    0.8118       129\n",
      "         124     0.8300    0.7757    0.8019       107\n",
      "         125     0.9140    0.9551    0.9341        89\n",
      "         126     0.7282    0.8523    0.7853        88\n",
      "         127     1.0000    0.9167    0.9565        12\n",
      "         128     0.3529    0.4615    0.4000        13\n",
      "         129     0.5556    0.5556    0.5556        18\n",
      "         130     0.9362    0.9565    0.9462        92\n",
      "         131     0.9542    0.9328    0.9434       134\n",
      "         132     0.8862    0.9801    0.9308       151\n",
      "         133     0.9273    0.9107    0.9189        56\n",
      "         134     0.7143    0.7692    0.7407        13\n",
      "         135     0.9541    0.9630    0.9585       108\n",
      "         136     0.9333    0.9333    0.9333        15\n",
      "         137     0.5946    0.8800    0.7097        25\n",
      "         138     0.9737    0.9673    0.9705       153\n",
      "         139     0.9697    0.9412    0.9552        34\n",
      "         140     0.7857    0.6286    0.6984        35\n",
      "         141     0.6562    0.8235    0.7304        51\n",
      "         142     0.9474    1.0000    0.9730        18\n",
      "         143     0.9386    0.9727    0.9554       110\n",
      "         144     0.9000    0.8182    0.8571        11\n",
      "         145     0.5000    0.5333    0.5161        15\n",
      "         146     0.8404    0.9186    0.8778        86\n",
      "         147     0.5769    0.6122    0.5941        49\n",
      "         148     0.7931    0.8846    0.8364        26\n",
      "         149     0.8301    0.8759    0.8523       145\n",
      "         150     0.5000    0.5918    0.5421        98\n",
      "         151     0.4545    0.5000    0.4762        10\n",
      "         152     0.8519    0.8846    0.8679        26\n",
      "         153     0.6667    0.6667    0.6667         6\n",
      "         154     0.7692    0.9091    0.8333        11\n",
      "         155     0.7778    0.6364    0.7000        11\n",
      "         156     0.7692    0.8333    0.8000        12\n",
      "         157     0.7241    0.9545    0.8235        22\n",
      "         158     1.0000    0.8000    0.8889        10\n",
      "         159     0.8571    0.8571    0.8571        21\n",
      "         160     0.9630    0.9630    0.9630        27\n",
      "         161     1.0000    0.7500    0.8571        12\n",
      "         162     0.7273    0.8000    0.7619        10\n",
      "         163     0.5414    0.7658    0.6343       111\n",
      "         164     0.5000    0.4706    0.4848        17\n",
      "         165     0.9187    0.9496    0.9339       119\n",
      "         166     0.7778    0.7778    0.7778         9\n",
      "         167     0.0000    0.0000    0.0000        20\n",
      "         168     0.8462    0.7333    0.7857        30\n",
      "         169     0.2500    0.1429    0.1818        14\n",
      "         170     0.6579    0.7812    0.7143        32\n",
      "         171     0.9848    0.9510    0.9676       204\n",
      "         172     0.9580    0.9960    0.9767       252\n",
      "         173     0.8974    0.9211    0.9091        38\n",
      "         174     0.6115    0.8727    0.7191       110\n",
      "         175     0.9286    0.8667    0.8966        15\n",
      "         176     1.0000    0.5556    0.7143         9\n",
      "         177     0.9592    0.9038    0.9307        52\n",
      "         178     0.8158    0.8611    0.8378        36\n",
      "         179     0.6667    0.6667    0.6667        24\n",
      "         180     0.8519    0.8214    0.8364        28\n",
      "         181     0.9474    0.9000    0.9231        20\n",
      "         182     0.4651    0.5882    0.5195        34\n",
      "         183     0.9292    0.9813    0.9545       107\n",
      "         184     0.8947    0.8095    0.8500        21\n",
      "         185     0.4600    0.4894    0.4742        47\n",
      "         186     0.9800    0.9751    0.9776       201\n",
      "         187     1.0000    0.9444    0.9714        18\n",
      "         188     0.5227    0.6389    0.5750        36\n",
      "         189     0.9149    0.9773    0.9451        88\n",
      "         190     0.7778    0.5000    0.6087        14\n",
      "         191     0.8333    1.0000    0.9091        10\n",
      "         192     1.0000    0.7273    0.8421        11\n",
      "         193     0.9730    0.9474    0.9600        76\n",
      "         194     0.9130    0.9545    0.9333        22\n",
      "         195     0.7778    0.7778    0.7778         9\n",
      "         196     0.8333    0.8333    0.8333        18\n",
      "         197     0.5000    0.3077    0.3810        13\n",
      "         198     0.9167    0.8462    0.8800        13\n",
      "         199     0.4872    0.4222    0.4524        45\n",
      "         200     0.9677    0.8571    0.9091        35\n",
      "         201     0.8571    0.8571    0.8571        14\n",
      "         202     0.9643    0.9310    0.9474        29\n",
      "         203     0.7826    0.9000    0.8372        20\n",
      "         204     0.7692    0.8333    0.8000        24\n",
      "         205     0.5714    0.4000    0.4706        10\n",
      "         206     0.9484    0.9608    0.9545       153\n",
      "         207     0.6667    0.5333    0.5926        30\n",
      "         208     0.9000    0.9000    0.9000        10\n",
      "         209     0.9600    0.9351    0.9474        77\n",
      "         210     0.9500    0.8906    0.9194        64\n",
      "         211     0.5814    0.6250    0.6024        40\n",
      "         212     1.0000    0.8824    0.9375        17\n",
      "         213     0.8333    0.8333    0.8333         6\n",
      "         214     0.8871    0.9649    0.9244        57\n",
      "         215     0.9375    0.9375    0.9375        16\n",
      "         216     1.0000    0.9000    0.9474        20\n",
      "         217     0.8579    0.9261    0.8907       176\n",
      "         218     0.9683    0.9104    0.9385        67\n",
      "         219     0.2500    0.0833    0.1250        24\n",
      "         220     0.8125    0.9286    0.8667        14\n",
      "         221     0.1250    0.0556    0.0769        18\n",
      "         222     0.9524    0.9524    0.9524        21\n",
      "         223     0.4000    0.2222    0.2857        27\n",
      "         224     0.9545    0.9130    0.9333        23\n",
      "         225     0.8235    1.0000    0.9032        14\n",
      "         226     0.0000    0.0000    0.0000        24\n",
      "         227     0.7986    0.9274    0.8582       124\n",
      "         228     0.8218    0.9022    0.8601        92\n",
      "         229     1.0000    0.9608    0.9800        51\n",
      "         230     0.9524    1.0000    0.9756        20\n",
      "         231     0.8077    1.0000    0.8936        21\n",
      "         232     0.8333    0.9091    0.8696        22\n",
      "         233     0.8000    0.9677    0.8759        62\n",
      "         234     0.7778    0.8235    0.8000        17\n",
      "         235     0.8889    0.6667    0.7619        12\n",
      "         236     0.5455    0.4286    0.4800        14\n",
      "         237     0.9231    0.8571    0.8889        14\n",
      "         238     0.5714    0.2353    0.3333        17\n",
      "         239     1.0000    0.9375    0.9677        16\n",
      "         240     0.8696    0.9524    0.9091        42\n",
      "         241     0.6364    0.7000    0.6667        10\n",
      "         242     0.8500    0.8947    0.8718        19\n",
      "         243     1.0000    1.0000    1.0000        14\n",
      "         244     1.0000    0.8333    0.9091        12\n",
      "         245     0.0000    0.0000    0.0000        28\n",
      "         246     0.9000    0.9818    0.9391        55\n",
      "         247     0.8750    0.7500    0.8077        28\n",
      "         248     0.7778    0.9333    0.8485        15\n",
      "         249     0.4348    0.1370    0.2083        73\n",
      "         250     0.9587    0.9766    0.9676       214\n",
      "         251     0.9778    0.8980    0.9362        49\n",
      "         252     0.7442    0.9412    0.8312        34\n",
      "         253     0.9540    0.9222    0.9379        90\n",
      "         254     0.9600    0.9231    0.9412        52\n",
      "         255     0.8571    0.9130    0.8842       230\n",
      "         256     0.9398    0.9542    0.9470       131\n",
      "         257     0.7429    0.7222    0.7324        36\n",
      "         258     0.9448    0.9786    0.9614       140\n",
      "         259     0.7778    0.5833    0.6667        12\n",
      "         260     0.5556    0.2632    0.3571        19\n",
      "         261     0.9355    0.9355    0.9355        31\n",
      "         262     0.9231    0.9474    0.9351        76\n",
      "         263     0.8235    0.8750    0.8485        16\n",
      "         264     0.8065    0.7143    0.7576        35\n",
      "         265     0.8889    0.9412    0.9143        17\n",
      "         266     0.7955    0.8333    0.8140        42\n",
      "         267     0.7778    0.9333    0.8485        15\n",
      "         268     0.9318    0.8913    0.9111        92\n",
      "         269     1.0000    1.0000    1.0000        26\n",
      "         270     0.5333    0.6275    0.5766        51\n",
      "         271     0.5455    0.4865    0.5143        37\n",
      "         272     0.8475    0.9434    0.8929        53\n",
      "         273     0.9726    0.9221    0.9467        77\n",
      "         274     0.7391    1.0000    0.8500        17\n",
      "         275     0.9535    1.0000    0.9762        41\n",
      "         276     0.9737    0.9250    0.9487        40\n",
      "         277     0.5556    0.3333    0.4167        15\n",
      "         278     0.8158    0.8158    0.8158        76\n",
      "         279     0.9497    0.9725    0.9610       291\n",
      "         280     0.7143    0.3333    0.4545        15\n",
      "         281     0.9091    0.8333    0.8696        24\n",
      "         282     0.3333    0.2727    0.3000        11\n",
      "         283     0.5000    0.5417    0.5200        24\n",
      "         284     0.2353    0.1538    0.1860        26\n",
      "         285     0.6000    0.4737    0.5294        95\n",
      "         286     0.8394    0.9426    0.8880       122\n",
      "         287     0.9000    0.6923    0.7826        13\n",
      "         288     0.8800    0.8148    0.8462        27\n",
      "         289     0.9560    0.9560    0.9560        91\n",
      "         290     0.9643    0.9643    0.9643        84\n",
      "         291     0.3889    0.2188    0.2800        32\n",
      "         292     0.9109    0.9388    0.9246        98\n",
      "         293     1.0000    0.8000    0.8889        10\n",
      "         294     0.9585    0.9541    0.9563       218\n",
      "         295     0.0000    0.0000    0.0000        19\n",
      "         296     0.9756    1.0000    0.9877        40\n",
      "         297     0.3333    0.2000    0.2500        15\n",
      "         298     0.2211    0.4565    0.2979        46\n",
      "         299     0.1667    0.0909    0.1176        11\n",
      "         300     1.0000    0.9583    0.9787        24\n",
      "         301     0.5909    0.7222    0.6500        36\n",
      "         302     0.6667    0.6250    0.6452        16\n",
      "         303     0.6190    0.7222    0.6667        18\n",
      "         304     0.6296    0.8500    0.7234        20\n",
      "         305     0.3684    0.2500    0.2979        28\n",
      "         306     0.7209    0.7949    0.7561        39\n",
      "         307     0.8571    0.5455    0.6667        11\n",
      "         308     0.8095    0.7083    0.7556        24\n",
      "         309     0.8209    0.7432    0.7801        74\n",
      "         310     0.7778    0.6364    0.7000        22\n",
      "         311     0.8889    0.7273    0.8000        33\n",
      "         312     0.7108    0.6782    0.6941        87\n",
      "         313     0.7812    0.6944    0.7353        36\n",
      "         314     0.8182    0.5625    0.6667        16\n",
      "         315     0.5263    0.5556    0.5405        18\n",
      "         316     0.5455    0.3333    0.4138        18\n",
      "         317     0.7500    0.8182    0.7826        11\n",
      "         318     0.0000    0.0000    0.0000        12\n",
      "         319     0.7778    0.4375    0.5600        16\n",
      "         320     0.6667    0.6667    0.6667        15\n",
      "         321     0.4667    0.6364    0.5385        11\n",
      "         322     0.6842    0.5909    0.6341        22\n",
      "         323     0.9000    0.8182    0.8571        11\n",
      "         324     0.7404    0.8105    0.7739        95\n",
      "         325     0.3000    0.1935    0.2353        31\n",
      "         326     0.9524    0.9524    0.9524        42\n",
      "         327     0.8000    0.8000    0.8000        20\n",
      "         328     0.8596    0.9608    0.9074       102\n",
      "         329     0.9524    1.0000    0.9756        20\n",
      "         330     0.7143    0.9091    0.8000        22\n",
      "         331     0.9225    1.0000    0.9597       238\n",
      "         332     0.9029    0.9208    0.9118       101\n",
      "         333     0.8125    0.6842    0.7429        19\n",
      "         334     0.6190    0.5909    0.6047        22\n",
      "         335     1.0000    0.7857    0.8800        14\n",
      "         336     0.3333    0.2000    0.2500        10\n",
      "         337     0.5455    0.4615    0.5000        13\n",
      "         338     0.8235    0.6667    0.7368        21\n",
      "         339     0.8434    0.8750    0.8589        80\n",
      "         340     0.5556    0.4545    0.5000        11\n",
      "         341     0.7500    0.6316    0.6857        19\n",
      "         342     0.9355    0.8788    0.9062        33\n",
      "         343     0.4925    0.4925    0.4925        67\n",
      "         344     0.3333    0.2727    0.3000        33\n",
      "         345     0.6471    0.8462    0.7333        13\n",
      "         346     0.7037    0.8261    0.7600        23\n",
      "         347     0.3214    0.3000    0.3103        30\n",
      "         348     0.2000    0.1429    0.1667        14\n",
      "         349     0.9000    0.9000    0.9000        10\n",
      "         350     0.7143    0.2778    0.4000        18\n",
      "         351     0.7500    0.5526    0.6364        38\n",
      "         352     0.2000    0.0714    0.1053        28\n",
      "         353     0.1111    0.1000    0.1053        20\n",
      "         354     0.8571    0.7500    0.8000        16\n",
      "         355     0.6400    0.5926    0.6154        27\n",
      "         356     0.5000    0.4000    0.4444         5\n",
      "         357     0.0000    0.0000    0.0000         5\n",
      "         358     0.5000    0.1429    0.2222         7\n",
      "         359     1.0000    0.8571    0.9231         7\n",
      "         360     0.3000    0.1250    0.1765        24\n",
      "         361     0.9091    0.8696    0.8889        23\n",
      "         362     1.0000    0.8000    0.8889        10\n",
      "         363     0.9306    0.8816    0.9054        76\n",
      "         364     0.0000    0.0000    0.0000        24\n",
      "         365     0.0882    0.0968    0.0923        31\n",
      "         366     0.7143    0.6897    0.7018        29\n",
      "         367     1.0000    1.0000    1.0000        15\n",
      "         368     0.9091    0.9091    0.9091        11\n",
      "\n",
      "    accuracy                         0.8132     16824\n",
      "   macro avg     0.7333    0.7032    0.7074     16824\n",
      "weighted avg     0.8026    0.8132    0.8033     16824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr10 = classification_report(y_true, y_pred, digits=4)\n",
    "print(cr10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym2latex = {i.Index : i.latex for i in symbols.itertuples()}\n",
    "latex2sym = {v: k for k, v in sym2latex.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ['hasyv2model41.h5']\n",
    "models = [load_model(model_dir+z) for z in ms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = [\n",
    "    'hasyv2model.h5',\n",
    "    'hasyv2model2.h5',\n",
    "    'hasyv2model3.h5',\n",
    "    'hasyv2model_stratified_kfold4.h5',\n",
    "    'hasyv2model_stratified_kfold5.h5',\n",
    "    'hasyv2model_stratified_kfold6.h5',\n",
    "    'hasyv2model_stratified_kfold7.h5',\n",
    "    'hasyv2model21.h5',\n",
    "    'hasyv2model.h5'\n",
    "     ]\n",
    "models = [load_model(model_dir+z) for z in ms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictng labels for Model 0\n",
      "Predictions Done\n",
      "Comparing Results...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>latex</th>\n",
       "      <th>model0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>\\approx</td>\n",
       "      <td>\\approx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>\\gamma</td>\n",
       "      <td>\\gamma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>\\Sigma</td>\n",
       "      <td>\\sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224</td>\n",
       "      <td>\\uparrow</td>\n",
       "      <td>\\uparrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>\\zeta</td>\n",
       "      <td>\\zeta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol     latex    model0\n",
       "0    171   \\approx   \\approx\n",
       "1     68    \\gamma    \\gamma\n",
       "2     67    \\Sigma      \\sum\n",
       "3    224  \\uparrow  \\uparrow\n",
       "4     72     \\zeta     \\zeta"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest = t_test(X_test, y_test, models=models, sym2latex_dict=sym2latex)\n",
    "ttest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latex</th>\n",
       "      <th>total_count</th>\n",
       "      <th>model0</th>\n",
       "      <th>model0_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>53.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  latex total_count model0  model0_acc\n",
       "0     A          16     10   62.500000\n",
       "1     B           6      3   50.000000\n",
       "2     C          13      7   53.846154\n",
       "3     D           6      3   50.000000\n",
       "4     E           5      5  100.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_report = create_t_test_report(ttest)\n",
    "t_test_report.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "* CNN1: CNN with two convolutional and two dense layers\n",
    "* CNN2: CNN with three convolutional and three dense layers\n",
    "* CNN3: CNN with three convolutional and three dense layers with Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "* model0: CNN1 on whole dataset\n",
    "* model1: CNN1 with random split on dataset\n",
    "* model2: CNN1 with stratified split on dataset\n",
    "* model3: CNN1 with K Fold cross validation\n",
    "* model4: CNN1 with K Fold cross vlidation\n",
    "* model5: CNN1 with K Fold cross validation\n",
    "* model6: CNN1 with K Fold cross validation\n",
    "* model7: CNN2 with stratified split on dataset\n",
    "* model8: CNN3 with stratified split on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latex</th>\n",
       "      <th>total_count</th>\n",
       "      <th>model0</th>\n",
       "      <th>model0_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>53.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>O</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>U</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>V</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>W</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>X</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Z</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\rightarrow</td>\n",
       "      <td>107</td>\n",
       "      <td>99</td>\n",
       "      <td>92.523364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>61.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\\pi</td>\n",
       "      <td>153</td>\n",
       "      <td>116</td>\n",
       "      <td>75.816993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\\alpha</td>\n",
       "      <td>260</td>\n",
       "      <td>205</td>\n",
       "      <td>78.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\\beta</td>\n",
       "      <td>113</td>\n",
       "      <td>97</td>\n",
       "      <td>85.840708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\\sum</td>\n",
       "      <td>340</td>\n",
       "      <td>277</td>\n",
       "      <td>81.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\\sigma</td>\n",
       "      <td>112</td>\n",
       "      <td>100</td>\n",
       "      <td>89.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>d</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>e</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>g</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>h</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>i</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>j</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>k</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>l</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>m</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>n</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>o</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>p</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>q</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>r</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>s</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>v</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>w</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>x</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>y</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>z</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\\Sigma</td>\n",
       "      <td>191</td>\n",
       "      <td>42</td>\n",
       "      <td>21.989529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>\\gamma</td>\n",
       "      <td>114</td>\n",
       "      <td>102</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>\\Gamma</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>88.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>\\delta</td>\n",
       "      <td>125</td>\n",
       "      <td>118</td>\n",
       "      <td>94.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>\\Delta</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>\\zeta</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>77.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>\\eta</td>\n",
       "      <td>69</td>\n",
       "      <td>67</td>\n",
       "      <td>97.101449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>\\theta</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>78.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>\\Theta</td>\n",
       "      <td>46</td>\n",
       "      <td>35</td>\n",
       "      <td>76.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>\\epsilon</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>9.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>\\varepsilon</td>\n",
       "      <td>74</td>\n",
       "      <td>52</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>\\iota</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>\\kappa</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>\\varkappa</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>35.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>\\lambda</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>\\Lambda</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>52.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>\\mu</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>95.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>\\nu</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>79.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>\\xi</td>\n",
       "      <td>257</td>\n",
       "      <td>238</td>\n",
       "      <td>92.607004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>\\Xi</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>\\Pi</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>13.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>\\rho</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>79.710145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>\\varrho</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>\\tau</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>\\phi</td>\n",
       "      <td>69</td>\n",
       "      <td>45</td>\n",
       "      <td>65.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>\\Phi</td>\n",
       "      <td>61</td>\n",
       "      <td>47</td>\n",
       "      <td>77.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>\\varphi</td>\n",
       "      <td>152</td>\n",
       "      <td>144</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>\\chi</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>81.720430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\psi</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\Psi</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\omega</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>96.825397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\Omega</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>71.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\partial</td>\n",
       "      <td>241</td>\n",
       "      <td>234</td>\n",
       "      <td>97.095436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>\\int</td>\n",
       "      <td>351</td>\n",
       "      <td>342</td>\n",
       "      <td>97.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>\\cdot</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>93.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>\\leq</td>\n",
       "      <td>105</td>\n",
       "      <td>84</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>\\geq</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>88.505747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>\\subset</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>96.103896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>\\supset</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>\\subseteq</td>\n",
       "      <td>158</td>\n",
       "      <td>152</td>\n",
       "      <td>96.202532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>\\supseteq</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>92.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>\\cong</td>\n",
       "      <td>140</td>\n",
       "      <td>133</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>\\propto</td>\n",
       "      <td>139</td>\n",
       "      <td>86</td>\n",
       "      <td>61.870504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>+</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>\\mathbb{R}</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>\\$</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>87.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\\{</td>\n",
       "      <td>114</td>\n",
       "      <td>103</td>\n",
       "      <td>90.350877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>\\copyright</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>\\dots</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>\\}</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>81.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>\\S</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>\\dag</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>\\pounds</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>\\&amp;</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>85.271318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>\\#</td>\n",
       "      <td>107</td>\n",
       "      <td>83</td>\n",
       "      <td>77.570093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>\\%</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>95.505618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>\\checkmark</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>85.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>\\circledR</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>91.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>\\mathsection</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>46.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>\\amalg</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>\\cup</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>95.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>\\oplus</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>93.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>\\times</td>\n",
       "      <td>151</td>\n",
       "      <td>148</td>\n",
       "      <td>98.013245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>\\ast</td>\n",
       "      <td>56</td>\n",
       "      <td>51</td>\n",
       "      <td>91.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>\\triangleleft</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>76.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>\\otimes</td>\n",
       "      <td>108</td>\n",
       "      <td>104</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>\\triangleright</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>\\diamond</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>\\pm</td>\n",
       "      <td>153</td>\n",
       "      <td>148</td>\n",
       "      <td>96.732026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>\\div</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>\\bullet</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>62.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>\\setminus</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>82.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>\\uplus</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>\\cap</td>\n",
       "      <td>110</td>\n",
       "      <td>107</td>\n",
       "      <td>97.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>\\mp</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>\\sqcap</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>53.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>\\vee</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>91.860465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>\\odot</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>61.224490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\\sqcup</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>88.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>\\wedge</td>\n",
       "      <td>145</td>\n",
       "      <td>127</td>\n",
       "      <td>87.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>\\circ</td>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>59.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>\\ominus</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>\\star</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>88.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>\\wr</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>\\barwedge</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>\\circledcirc</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>\\boxdot</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>\\ltimes</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>95.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>\\boxplus</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>\\boxtimes</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>\\rtimes</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>96.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>\\circledast</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>\\lhd</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>\\prod</td>\n",
       "      <td>111</td>\n",
       "      <td>85</td>\n",
       "      <td>76.576577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>\\coprod</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>47.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>\\oint</td>\n",
       "      <td>119</td>\n",
       "      <td>113</td>\n",
       "      <td>94.957983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>\\parr</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>\\with</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>\\fint</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>\\varoiint</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>\\oiint</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>78.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>\\approx</td>\n",
       "      <td>204</td>\n",
       "      <td>194</td>\n",
       "      <td>95.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>\\equiv</td>\n",
       "      <td>252</td>\n",
       "      <td>251</td>\n",
       "      <td>99.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>\\not\\equiv</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>92.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>\\perp</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>87.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>\\asymp</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>86.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>\\frown</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>\\prec</td>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>90.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>\\succ</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>\\bowtie</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>\\preceq</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>82.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>\\succeq</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>\\mid</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>58.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>\\vdash</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>98.130841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>\\dashv</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>\\models</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>48.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>\\sim</td>\n",
       "      <td>201</td>\n",
       "      <td>196</td>\n",
       "      <td>97.512438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>\\doteq</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>\\parallel</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>63.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>\\simeq</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>97.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>\\backsim</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>\\multimap</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>\\pitchfork</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>72.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>\\therefore</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>\\because</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>95.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>\\between</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>\\preccurlyeq</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>\\varpropto</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>30.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>\\Vdash</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>84.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>\\vDash</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>42.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>\\nmid</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>\\nvDash</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>\\sqsubseteq</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>93.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>\\nsubseteq</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>\\subsetneq</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>\\varsubsetneq</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>\\neq</td>\n",
       "      <td>153</td>\n",
       "      <td>147</td>\n",
       "      <td>96.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>\\geqslant</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>53.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>\\gtrless</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>\\lesssim</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>93.506494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>\\gtrsim</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>89.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>\\leqslant</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>\\trianglelefteq</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>88.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>\\blacktriangleright</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>\\triangleq</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>96.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>\\Downarrow</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>\\downarrow</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>\\Rightarrow</td>\n",
       "      <td>176</td>\n",
       "      <td>163</td>\n",
       "      <td>92.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>\\hookrightarrow</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>91.044776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>\\Longleftrightarrow</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>\\searrow</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>92.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>\\longmapsto</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>\\leftarrow</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>\\Longrightarrow</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>\\uparrow</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>91.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>\\Leftarrow</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>\\longrightarrow</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>\\Leftrightarrow</td>\n",
       "      <td>124</td>\n",
       "      <td>115</td>\n",
       "      <td>92.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>\\mapsto</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>90.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>\\leftrightarrow</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>96.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>\\nearrow</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>\\rightleftharpoons</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>\\rightharpoonup</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>\\leadsto</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>96.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>\\circlearrowleft</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>82.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>\\rightleftarrows</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>\\circlearrowright</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>42.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>\\rightrightarrows</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>\\rightsquigarrow</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>23.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>\\curvearrowright</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>\\twoheadrightarrow</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>\\nRightarrow</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>\\nrightarrow</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>89.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>\\upharpoonright</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>\\mapsfrom</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>\\shortrightarrow</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>\\lightning</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>98.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>\\vartheta</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>\\varpi</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>\\bot</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>13.698630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>\\forall</td>\n",
       "      <td>214</td>\n",
       "      <td>209</td>\n",
       "      <td>97.663551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>\\ni</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>89.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>\\top</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>\\ell</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "      <td>92.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>\\hbar</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>92.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>\\in</td>\n",
       "      <td>230</td>\n",
       "      <td>210</td>\n",
       "      <td>91.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>\\notin</td>\n",
       "      <td>131</td>\n",
       "      <td>125</td>\n",
       "      <td>95.419847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>\\wp</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>72.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>\\exists</td>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>97.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>\\Im</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>\\Re</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>26.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>\\nexists</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>93.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>\\langle</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>94.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>\\rangle</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\\lceil</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>\\rceil</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>94.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>\\lfloor</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>\\rfloor</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>[</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>89.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>]</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>|</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>62.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>\\|</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>48.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>/</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>94.339623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>\\llbracket</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>92.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>\\rrbracket</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>\\vdots</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>\\ddots</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>92.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>\\dotsc</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>\\aleph</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>81.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>\\infty</td>\n",
       "      <td>291</td>\n",
       "      <td>283</td>\n",
       "      <td>97.250859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>\\prime</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>\\angle</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>\\diamondsuit</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>\\sharp</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>54.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>\\backslash</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>\\emptyset</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>47.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>\\nabla</td>\n",
       "      <td>122</td>\n",
       "      <td>115</td>\n",
       "      <td>94.262295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>\\flat</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>69.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>\\clubsuit</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>81.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>\\heartsuit</td>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>95.604396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>\\neg</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>96.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>\\triangle</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>21.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>\\sqrt{}</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>93.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>\\sphericalangle</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>\\square</td>\n",
       "      <td>218</td>\n",
       "      <td>208</td>\n",
       "      <td>95.412844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>\\triangledown</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>\\blacksquare</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>\\lozenge</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>\\varnothing</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>45.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>\\vartriangle</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>\\iddots</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>95.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>\\mathcal{A}</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>72.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>\\mathcal{B}</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>\\mathcal{C}</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>72.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>\\mathcal{D}</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>\\mathcal{E}</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>\\mathcal{F}</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>79.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>\\mathcal{G}</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>\\mathcal{H}</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>70.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>\\mathcal{L}</td>\n",
       "      <td>74</td>\n",
       "      <td>55</td>\n",
       "      <td>74.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>\\mathcal{M}</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>\\mathcal{N}</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>72.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>\\mathcal{O}</td>\n",
       "      <td>87</td>\n",
       "      <td>59</td>\n",
       "      <td>67.816092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>\\mathcal{P}</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>69.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>\\mathcal{R}</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>56.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>\\mathcal{S}</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>\\mathcal{T}</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>\\mathcal{U}</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>\\mathcal{X}</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>\\mathcal{Z}</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>43.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>\\mathfrak{A}</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>\\mathfrak{M}</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>\\mathfrak{S}</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>59.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>\\mathfrak{X}</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>81.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>\\mathbb{1}</td>\n",
       "      <td>95</td>\n",
       "      <td>77</td>\n",
       "      <td>81.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>\\mathds{1}</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>19.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>\\mathds{C}</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>\\mathds{E}</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>\\mathds{N}</td>\n",
       "      <td>102</td>\n",
       "      <td>98</td>\n",
       "      <td>96.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>\\mathds{P}</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>\\mathds{Q}</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>\\mathds{R}</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>\\mathds{Z}</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>92.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>\\mathscr{A}</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>68.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>\\mathscr{C}</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>59.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>\\mathscr{D}</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>\\mathscr{E}</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>\\mathscr{F}</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>46.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>\\mathscr{H}</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>\\mathscr{L}</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>87.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>\\mathscr{P}</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>\\mathscr{S}</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>63.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>\\celsius</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>87.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>\\degree</td>\n",
       "      <td>67</td>\n",
       "      <td>33</td>\n",
       "      <td>49.253731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>\\ohm</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>\\venus</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>84.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>\\mars</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>82.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>\\astrosun</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>\\fullmoon</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>\\leftmoon</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>\\female</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>27.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>\\male</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>55.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>\\checked</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>\\diameter</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>\\sun</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>\\Bowtie</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>59.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>\\mathbb{Q}</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>\\mathbb{N}</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>\\mathbb{Z}</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>\\mathbb{H}</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>\\ss</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>\\aa</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>86.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>\\L</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>\\AA</td>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>88.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>\\O</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>\\o</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>9.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>\\ae</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>68.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>\\AE</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>\\guillemotleft</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>90.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   latex total_count model0  model0_acc\n",
       "0                      A          16     10   62.500000\n",
       "1                      B           6      3   50.000000\n",
       "2                      C          13      7   53.846154\n",
       "3                      D           6      3   50.000000\n",
       "4                      E           5      5  100.000000\n",
       "5                      F           6      4   66.666667\n",
       "6                      G          12     11   91.666667\n",
       "7                      H           6      4   66.666667\n",
       "8                      I          10      4   40.000000\n",
       "9                      J          10      8   80.000000\n",
       "10                     K          10      9   90.000000\n",
       "11                     L          11      6   54.545455\n",
       "12                     M          12     10   83.333333\n",
       "13                     N          10      7   70.000000\n",
       "14                     O           8      2   25.000000\n",
       "15                     P           7      5   71.428571\n",
       "16                     Q           7      3   42.857143\n",
       "17                     R           8      6   75.000000\n",
       "18                     S           6      1   16.666667\n",
       "19                     T           6      0    0.000000\n",
       "20                     U           6      2   33.333333\n",
       "21                     V           6      1   16.666667\n",
       "22                     W           6      2   33.333333\n",
       "23                     X           5      2   40.000000\n",
       "24                     Y           6      2   33.333333\n",
       "25                     Z           6      3   50.000000\n",
       "26           \\rightarrow         107     99   92.523364\n",
       "27                     0          13      8   61.538462\n",
       "28                     1          12      9   75.000000\n",
       "29                     2          12     12  100.000000\n",
       "30                     3          12      8   66.666667\n",
       "31                     4           6      6  100.000000\n",
       "32                     5           8      4   50.000000\n",
       "33                     6          10      6   60.000000\n",
       "34                     7           7      6   85.714286\n",
       "35                     8          12      7   58.333333\n",
       "36                     9           9      2   22.222222\n",
       "37                   \\pi         153    116   75.816993\n",
       "38                \\alpha         260    205   78.846154\n",
       "39                 \\beta         113     97   85.840708\n",
       "40                  \\sum         340    277   81.470588\n",
       "41                \\sigma         112    100   89.285714\n",
       "42                     a           9      5   55.555556\n",
       "43                     b           6      5   83.333333\n",
       "44                     c           7      2   28.571429\n",
       "45                     d           6      6  100.000000\n",
       "46                     e           6      3   50.000000\n",
       "47                     f           7      5   71.428571\n",
       "48                     g           6      2   33.333333\n",
       "49                     h           6      6  100.000000\n",
       "50                     i           6      6  100.000000\n",
       "51                     j           5      4   80.000000\n",
       "52                     k           6      5   83.333333\n",
       "53                     l           6      1   16.666667\n",
       "54                     m           6      2   33.333333\n",
       "55                     n           6      3   50.000000\n",
       "56                     o           6      0    0.000000\n",
       "57                     p           5      4   80.000000\n",
       "58                     q           7      5   71.428571\n",
       "59                     r           6      4   66.666667\n",
       "60                     s           6      5   83.333333\n",
       "61                     u           6      2   33.333333\n",
       "62                     v           6      1   16.666667\n",
       "63                     w           6      2   33.333333\n",
       "64                     x           7      0    0.000000\n",
       "65                     y           6      3   50.000000\n",
       "66                     z           6      0    0.000000\n",
       "67                \\Sigma         191     42   21.989529\n",
       "68                \\gamma         114    102   89.473684\n",
       "69                \\Gamma          62     55   88.709677\n",
       "70                \\delta         125    118   94.400000\n",
       "71                \\Delta         100     81   81.000000\n",
       "72                 \\zeta          87     67   77.011494\n",
       "73                  \\eta          69     67   97.101449\n",
       "74                \\theta          65     51   78.461538\n",
       "75                \\Theta          46     35   76.086957\n",
       "76              \\epsilon          54      5    9.259259\n",
       "77           \\varepsilon          74     52   70.270270\n",
       "78                 \\iota          16     15   93.750000\n",
       "79                \\kappa          25     15   60.000000\n",
       "80             \\varkappa          14      5   35.714286\n",
       "81               \\lambda         100     93   93.000000\n",
       "82               \\Lambda          44     23   52.272727\n",
       "83                   \\mu         115    110   95.652174\n",
       "84                   \\nu          39     31   79.487179\n",
       "85                   \\xi         257    238   92.607004\n",
       "86                   \\Xi          40     38   95.000000\n",
       "87                   \\Pi          80     11   13.750000\n",
       "88                  \\rho          69     55   79.710145\n",
       "89               \\varrho          22     14   63.636364\n",
       "90                  \\tau          42     32   76.190476\n",
       "91                  \\phi          69     45   65.217391\n",
       "92                  \\Phi          61     47   77.049180\n",
       "93               \\varphi         152    144   94.736842\n",
       "94                  \\chi          93     76   81.720430\n",
       "95                  \\psi          56     40   71.428571\n",
       "96                  \\Psi          45     30   66.666667\n",
       "97                \\omega          63     61   96.825397\n",
       "98                \\Omega          82     59   71.951220\n",
       "99              \\partial         241    234   97.095436\n",
       "100                 \\int         351    342   97.435897\n",
       "101                \\cdot          76     71   93.421053\n",
       "102                 \\leq         105     84   80.000000\n",
       "103                 \\geq          87     77   88.505747\n",
       "104                    <          11      9   81.818182\n",
       "105                    >          10      7   70.000000\n",
       "106              \\subset          77     74   96.103896\n",
       "107              \\supset          41     41  100.000000\n",
       "108            \\subseteq         158    152   96.202532\n",
       "109            \\supseteq          40     37   92.500000\n",
       "110                \\cong         140    133   95.000000\n",
       "111              \\propto         139     86   61.870504\n",
       "112                    -          12     12  100.000000\n",
       "113                    +           9      8   88.888889\n",
       "114           \\mathbb{R}           6      0    0.000000\n",
       "115                   \\$          39     34   87.179487\n",
       "116                   \\{         114    103   90.350877\n",
       "117           \\copyright          24     22   91.666667\n",
       "118                \\dots          14     11   78.571429\n",
       "119                   \\}          32     26   81.250000\n",
       "120                   \\S          35     21   60.000000\n",
       "121                 \\dag          25     24   96.000000\n",
       "122              \\pounds          15     13   86.666667\n",
       "123                   \\&         129    110   85.271318\n",
       "124                   \\#         107     83   77.570093\n",
       "125                   \\%          89     85   95.505618\n",
       "126           \\checkmark          88     75   85.227273\n",
       "127            \\circledR          12     11   91.666667\n",
       "128         \\mathsection          13      6   46.153846\n",
       "129               \\amalg          18     10   55.555556\n",
       "130                 \\cup          92     88   95.652174\n",
       "131               \\oplus         134    125   93.283582\n",
       "132               \\times         151    148   98.013245\n",
       "133                 \\ast          56     51   91.071429\n",
       "134        \\triangleleft          13     10   76.923077\n",
       "135              \\otimes         108    104   96.296296\n",
       "136       \\triangleright          15     14   93.333333\n",
       "137             \\diamond          25     22   88.000000\n",
       "138                  \\pm         153    148   96.732026\n",
       "139                 \\div          34     32   94.117647\n",
       "140              \\bullet          35     22   62.857143\n",
       "141            \\setminus          51     42   82.352941\n",
       "142               \\uplus          18     18  100.000000\n",
       "143                 \\cap         110    107   97.272727\n",
       "144                  \\mp          11      9   81.818182\n",
       "145               \\sqcap          15      8   53.333333\n",
       "146                 \\vee          86     79   91.860465\n",
       "147                \\odot          49     30   61.224490\n",
       "148               \\sqcup          26     23   88.461538\n",
       "149               \\wedge         145    127   87.586207\n",
       "150                \\circ          98     58   59.183673\n",
       "151              \\ominus          10      5   50.000000\n",
       "152                \\star          26     23   88.461538\n",
       "153                  \\wr           6      4   66.666667\n",
       "154            \\barwedge          11     10   90.909091\n",
       "155         \\circledcirc          11      7   63.636364\n",
       "156              \\boxdot          12     10   83.333333\n",
       "157              \\ltimes          22     21   95.454545\n",
       "158             \\boxplus          10      8   80.000000\n",
       "159            \\boxtimes          21     18   85.714286\n",
       "160              \\rtimes          27     26   96.296296\n",
       "161          \\circledast          12      9   75.000000\n",
       "162                 \\lhd          10      8   80.000000\n",
       "163                \\prod         111     85   76.576577\n",
       "164              \\coprod          17      8   47.058824\n",
       "165                \\oint         119    113   94.957983\n",
       "166                \\parr           9      7   77.777778\n",
       "167                \\with          20      0    0.000000\n",
       "168                \\fint          30     22   73.333333\n",
       "169            \\varoiint          14      2   14.285714\n",
       "170               \\oiint          32     25   78.125000\n",
       "171              \\approx         204    194   95.098039\n",
       "172               \\equiv         252    251   99.603175\n",
       "173           \\not\\equiv          38     35   92.105263\n",
       "174                \\perp         110     96   87.272727\n",
       "175               \\asymp          15     13   86.666667\n",
       "176               \\frown           9      5   55.555556\n",
       "177                \\prec          52     47   90.384615\n",
       "178                \\succ          36     31   86.111111\n",
       "179              \\bowtie          24     16   66.666667\n",
       "180              \\preceq          28     23   82.142857\n",
       "181              \\succeq          20     18   90.000000\n",
       "182                 \\mid          34     20   58.823529\n",
       "183               \\vdash         107    105   98.130841\n",
       "184               \\dashv          21     17   80.952381\n",
       "185              \\models          47     23   48.936170\n",
       "186                 \\sim         201    196   97.512438\n",
       "187               \\doteq          18     17   94.444444\n",
       "188            \\parallel          36     23   63.888889\n",
       "189               \\simeq          88     86   97.727273\n",
       "190             \\backsim          14      7   50.000000\n",
       "191            \\multimap          10     10  100.000000\n",
       "192           \\pitchfork          11      8   72.727273\n",
       "193           \\therefore          76     72   94.736842\n",
       "194             \\because          22     21   95.454545\n",
       "195             \\between           9      7   77.777778\n",
       "196         \\preccurlyeq          18     15   83.333333\n",
       "197           \\varpropto          13      4   30.769231\n",
       "198               \\Vdash          13     11   84.615385\n",
       "199               \\vDash          45     19   42.222222\n",
       "200                \\nmid          35     30   85.714286\n",
       "201              \\nvDash          14     12   85.714286\n",
       "202          \\sqsubseteq          29     27   93.103448\n",
       "203           \\nsubseteq          20     18   90.000000\n",
       "204           \\subsetneq          24     20   83.333333\n",
       "205        \\varsubsetneq          10      4   40.000000\n",
       "206                 \\neq         153    147   96.078431\n",
       "207            \\geqslant          30     16   53.333333\n",
       "208             \\gtrless          10      9   90.000000\n",
       "209             \\lesssim          77     72   93.506494\n",
       "210              \\gtrsim          64     57   89.062500\n",
       "211            \\leqslant          40     25   62.500000\n",
       "212      \\trianglelefteq          17     15   88.235294\n",
       "213  \\blacktriangleright           6      5   83.333333\n",
       "214           \\triangleq          57     55   96.491228\n",
       "215           \\Downarrow          16     15   93.750000\n",
       "216           \\downarrow          20     18   90.000000\n",
       "217          \\Rightarrow         176    163   92.613636\n",
       "218      \\hookrightarrow          67     61   91.044776\n",
       "219  \\Longleftrightarrow          24      2    8.333333\n",
       "220             \\searrow          14     13   92.857143\n",
       "221          \\longmapsto          18      1    5.555556\n",
       "222           \\leftarrow          21     20   95.238095\n",
       "223      \\Longrightarrow          27      6   22.222222\n",
       "224             \\uparrow          23     21   91.304348\n",
       "225           \\Leftarrow          14     14  100.000000\n",
       "226      \\longrightarrow          24      0    0.000000\n",
       "227      \\Leftrightarrow         124    115   92.741935\n",
       "228              \\mapsto          92     83   90.217391\n",
       "229      \\leftrightarrow          51     49   96.078431\n",
       "230             \\nearrow          20     20  100.000000\n",
       "231   \\rightleftharpoons          21     21  100.000000\n",
       "232      \\rightharpoonup          22     20   90.909091\n",
       "233             \\leadsto          62     60   96.774194\n",
       "234     \\circlearrowleft          17     14   82.352941\n",
       "235     \\rightleftarrows          12      8   66.666667\n",
       "236    \\circlearrowright          14      6   42.857143\n",
       "237    \\rightrightarrows          14     12   85.714286\n",
       "238     \\rightsquigarrow          17      4   23.529412\n",
       "239     \\curvearrowright          16     15   93.750000\n",
       "240   \\twoheadrightarrow          42     40   95.238095\n",
       "241         \\nRightarrow          10      7   70.000000\n",
       "242         \\nrightarrow          19     17   89.473684\n",
       "243      \\upharpoonright          14     14  100.000000\n",
       "244            \\mapsfrom          12     10   83.333333\n",
       "245     \\shortrightarrow          28      0    0.000000\n",
       "246           \\lightning          55     54   98.181818\n",
       "247            \\vartheta          28     21   75.000000\n",
       "248               \\varpi          15     14   93.333333\n",
       "249                 \\bot          73     10   13.698630\n",
       "250              \\forall         214    209   97.663551\n",
       "251                  \\ni          49     44   89.795918\n",
       "252                 \\top          34     32   94.117647\n",
       "253                 \\ell          90     83   92.222222\n",
       "254                \\hbar          52     48   92.307692\n",
       "255                  \\in         230    210   91.304348\n",
       "256               \\notin         131    125   95.419847\n",
       "257                  \\wp          36     26   72.222222\n",
       "258              \\exists         140    137   97.857143\n",
       "259                  \\Im          12      7   58.333333\n",
       "260                  \\Re          19      5   26.315789\n",
       "261             \\nexists          31     29   93.548387\n",
       "262              \\langle          76     72   94.736842\n",
       "263              \\rangle          16     14   87.500000\n",
       "264               \\lceil          35     25   71.428571\n",
       "265               \\rceil          17     16   94.117647\n",
       "266              \\lfloor          42     35   83.333333\n",
       "267              \\rfloor          15     14   93.333333\n",
       "268                    [          92     82   89.130435\n",
       "269                    ]          26     26  100.000000\n",
       "270                    |          51     32   62.745098\n",
       "271                   \\|          37     18   48.648649\n",
       "272                    /          53     50   94.339623\n",
       "273           \\llbracket          77     71   92.207792\n",
       "274           \\rrbracket          17     17  100.000000\n",
       "275               \\vdots          41     41  100.000000\n",
       "276               \\ddots          40     37   92.500000\n",
       "277               \\dotsc          15      5   33.333333\n",
       "278               \\aleph          76     62   81.578947\n",
       "279               \\infty         291    283   97.250859\n",
       "280               \\prime          15      5   33.333333\n",
       "281               \\angle          24     20   83.333333\n",
       "282         \\diamondsuit          11      3   27.272727\n",
       "283               \\sharp          24     13   54.166667\n",
       "284           \\backslash          26      4   15.384615\n",
       "285            \\emptyset          95     45   47.368421\n",
       "286               \\nabla         122    115   94.262295\n",
       "287                \\flat          13      9   69.230769\n",
       "288            \\clubsuit          27     22   81.481481\n",
       "289           \\heartsuit          91     87   95.604396\n",
       "290                 \\neg          84     81   96.428571\n",
       "291            \\triangle          32      7   21.875000\n",
       "292              \\sqrt{}          98     92   93.877551\n",
       "293      \\sphericalangle          10      8   80.000000\n",
       "294              \\square         218    208   95.412844\n",
       "295        \\triangledown          19      0    0.000000\n",
       "296         \\blacksquare          40     40  100.000000\n",
       "297             \\lozenge          15      3   20.000000\n",
       "298          \\varnothing          46     21   45.652174\n",
       "299         \\vartriangle          11      1    9.090909\n",
       "300              \\iddots          24     23   95.833333\n",
       "301          \\mathcal{A}          36     26   72.222222\n",
       "302          \\mathcal{B}          16     10   62.500000\n",
       "303          \\mathcal{C}          18     13   72.222222\n",
       "304          \\mathcal{D}          20     17   85.000000\n",
       "305          \\mathcal{E}          28      7   25.000000\n",
       "306          \\mathcal{F}          39     31   79.487179\n",
       "307          \\mathcal{G}          11      6   54.545455\n",
       "308          \\mathcal{H}          24     17   70.833333\n",
       "309          \\mathcal{L}          74     55   74.324324\n",
       "310          \\mathcal{M}          22     14   63.636364\n",
       "311          \\mathcal{N}          33     24   72.727273\n",
       "312          \\mathcal{O}          87     59   67.816092\n",
       "313          \\mathcal{P}          36     25   69.444444\n",
       "314          \\mathcal{R}          16      9   56.250000\n",
       "315          \\mathcal{S}          18     10   55.555556\n",
       "316          \\mathcal{T}          18      6   33.333333\n",
       "317          \\mathcal{U}          11      9   81.818182\n",
       "318          \\mathcal{X}          12      0    0.000000\n",
       "319          \\mathcal{Z}          16      7   43.750000\n",
       "320         \\mathfrak{A}          15     10   66.666667\n",
       "321         \\mathfrak{M}          11      7   63.636364\n",
       "322         \\mathfrak{S}          22     13   59.090909\n",
       "323         \\mathfrak{X}          11      9   81.818182\n",
       "324           \\mathbb{1}          95     77   81.052632\n",
       "325           \\mathds{1}          31      6   19.354839\n",
       "326           \\mathds{C}          42     40   95.238095\n",
       "327           \\mathds{E}          20     16   80.000000\n",
       "328           \\mathds{N}         102     98   96.078431\n",
       "329           \\mathds{P}          20     20  100.000000\n",
       "330           \\mathds{Q}          22     20   90.909091\n",
       "331           \\mathds{R}         238    238  100.000000\n",
       "332           \\mathds{Z}         101     93   92.079208\n",
       "333          \\mathscr{A}          19     13   68.421053\n",
       "334          \\mathscr{C}          22     13   59.090909\n",
       "335          \\mathscr{D}          14     11   78.571429\n",
       "336          \\mathscr{E}          10      2   20.000000\n",
       "337          \\mathscr{F}          13      6   46.153846\n",
       "338          \\mathscr{H}          21     14   66.666667\n",
       "339          \\mathscr{L}          80     70   87.500000\n",
       "340          \\mathscr{P}          11      5   45.454545\n",
       "341          \\mathscr{S}          19     12   63.157895\n",
       "342             \\celsius          33     29   87.878788\n",
       "343              \\degree          67     33   49.253731\n",
       "344                 \\ohm          33      9   27.272727\n",
       "345               \\venus          13     11   84.615385\n",
       "346                \\mars          23     19   82.608696\n",
       "347            \\astrosun          30      9   30.000000\n",
       "348            \\fullmoon          14      2   14.285714\n",
       "349            \\leftmoon          10      9   90.000000\n",
       "350              \\female          18      5   27.777778\n",
       "351                \\male          38     21   55.263158\n",
       "352             \\checked          28      2    7.142857\n",
       "353            \\diameter          20      2   10.000000\n",
       "354                 \\sun          16     12   75.000000\n",
       "355              \\Bowtie          27     16   59.259259\n",
       "356           \\mathbb{Q}           5      2   40.000000\n",
       "357           \\mathbb{N}           5      0    0.000000\n",
       "358           \\mathbb{Z}           7      1   14.285714\n",
       "359           \\mathbb{H}           7      6   85.714286\n",
       "360                  \\ss          24      3   12.500000\n",
       "361                  \\aa          23     20   86.956522\n",
       "362                   \\L          10      8   80.000000\n",
       "363                  \\AA          76     67   88.157895\n",
       "364                   \\O          24      0    0.000000\n",
       "365                   \\o          31      3    9.677419\n",
       "366                  \\ae          29     20   68.965517\n",
       "367                  \\AE          15     15  100.000000\n",
       "368       \\guillemotleft          11     10   90.909091"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
