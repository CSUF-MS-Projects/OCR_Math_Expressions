{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from enum import Enum\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anytree import Node, RenderTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(Enum):\n",
    "    INITIAL = 0, 'INITIAL'\n",
    "    IDENTIFIER_START = 1, 'IDENTIFIER_START'\n",
    "    IDENITIFIER_END = 2, 'IDENTIFIER_END'\n",
    "    INTEGER_START = 3, 'INTEGER_START'\n",
    "    INTEGER_END = 4, 'INTEGER_END'\n",
    "    REAL_START = 5, 'REAL_START'\n",
    "    REAL_IN = 6, 'REAL_IN'\n",
    "    REAL_END = 7, 'REAL_END'\n",
    "    SEPARATOR = 8, 'SEPARATOR'\n",
    "    OPERATOR = 9, 'OPERATOR'\n",
    "    SEPCIAL_CHARACTER = 10, 'SPECIAL_CHARACTER'\n",
    "    DEAD = 11, 'DEAD_STATE'\n",
    "    \n",
    "    def __new__(cls, value, name):\n",
    "        x = object.__new__(cls)\n",
    "        x._value_ = value\n",
    "        x._name = name\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self.value\n",
    "\n",
    "class Input(Enum):\n",
    "    LETTER = 0, 'LETTER'\n",
    "    DIGIT = 1, 'DIGIT'\n",
    "    DOT = 2, 'DOT'\n",
    "    SEP = 3, 'SEP'\n",
    "    OP = 4, 'OP'\n",
    "    SPECIAL = 5, 'SPECIAL'\n",
    "    \n",
    "    def __new__(cls, value, name):\n",
    "        x = object.__new__(cls)\n",
    "        x._value_ = value\n",
    "        x._name = name\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self.value\n",
    "    \n",
    "class Token():\n",
    "    def __init__(self, **kwargs):\n",
    "        self._value = kwargs['value']\n",
    "        if self._value == 0:\n",
    "            self._name = 'IDENTIFIER'\n",
    "        elif self._value == 1:\n",
    "            self._name = 'KEYWORD'\n",
    "        elif self._value == 2:\n",
    "            self._name = 'INTEGER'\n",
    "        elif self._value == 3:\n",
    "            self._name = 'REAL'\n",
    "        elif self._value == 4:\n",
    "            self._name = 'SEPARATOR'\n",
    "        elif self._value == 5:\n",
    "            self._name = 'OPERATOR'\n",
    "        elif self._value == 6:\n",
    "            self._name = 'SPECIAL'\n",
    "        else:\n",
    "            raise ValueError('value should be within 0 and 5')\n",
    "        self._lexeme = kwargs['lexeme']\n",
    "    \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self._value\n",
    "    \n",
    "    @property\n",
    "    def lexeme(self):\n",
    "        return self._lexeme\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "SEPARATORS = ['\\(','\\)','[',']','\\{','\\}','.',',',':',';',' ','\\cdot']\n",
    "OPERATORS = ['+','-','=','/','>','<','%',' ','\\&','\\times','\\div','\\ast','\\cup','\\cap','\\subset','\\supset','\\subseteq','\\|','\\perp','\\eq','\\geq']\n",
    "STATE_TABLE_DATA = [\n",
    "    [1,3,11,8,9,10],\n",
    "    [1,2,11,2,2,2],\n",
    "    [0,0,0,0,0,0],\n",
    "    [4,3,5,4,4,4],\n",
    "    [0,0,0,0,0,0],\n",
    "    [11,6,11,11,11,11],\n",
    "    [7,6,7,7,7,7],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0]\n",
    "]\n",
    "STATE_TABLE = [[None for i in range(len(STATE_TABLE_DATA[0]))] for j in range(len(STATE_TABLE_DATA))]\n",
    "for i in range(len(STATE_TABLE_DATA)):\n",
    "    for j in range(len(STATE_TABLE_DATA[0])):\n",
    "        STATE_TABLE[i][j] = State(STATE_TABLE_DATA[i][j])\n",
    "\n",
    "KEYWORDS = ['sin','cos','tan','sinh','cosh','tanh','and','or']\n",
    "GREEKS = [r'\\sigma',r'\\Sigma',r'\\gamma',r'\\delta',r'\\Delta',r'\\eta',r'\\theta',r'\\epsilon',r'\\lambda',r'\\mu',r'\\Pi',r'\\rho',r'\\phi',r'\\omega',r'\\ohm']\n",
    "SPECIAL_CHARS = ['\\infty','\\exists','\\forall','\\#','\\$'] + GREEKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_characters = lambda chars: [c if c not in ['\\n', '\\t', '\\r'] else ' ' for c in chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkLetter = lambda chars: True if re.match(\"[a-zA-Z]\", chars) else False\n",
    "checkDigit = lambda chars: True if re.match(\"[0-9]\", chars) else False\n",
    "checkDollar = lambda chars: True if chars in ['$'] else False\n",
    "checkDot = lambda chars: True if chars in ['.','\\cdot'] else False\n",
    "checkSep = lambda chars: True if chars in SEPARATORS else False\n",
    "checkOp = lambda chars: True if chars in OPERATORS else False\n",
    "checkSpecial = lambda chars: True if chars in SPECIAL_CHARS else False\n",
    "checkEscape = lambda chars: True if chars in [\"\\\\\"] else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks each input and returns an instance of input class\n",
    "def checkInput(chars):\n",
    "    if checkLetter(chars):\n",
    "        return Input.LETTER\n",
    "    elif checkDigit(chars):\n",
    "        return Input.DIGIT\n",
    "    elif checkDollar(chars):\n",
    "        return Input.DOLLAR\n",
    "    elif checkDot(chars):\n",
    "        return Input.DOT\n",
    "    elif checkSep(chars):\n",
    "        return Input.SEP\n",
    "    elif checkOp(chars):\n",
    "        return Input.OP\n",
    "    elif checkSpecial(chars):\n",
    "        return Input.SPECIAL\n",
    "    else:\n",
    "        raise ValueError(\"INVALID INPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexer(expression):\n",
    "    expression = expression + [' '] # added this because integers, letters and real require a separator at the end to move to final state\n",
    "    prev_state = State.INITIAL\n",
    "    lexeme = ''\n",
    "    tokens = []\n",
    "    i = 0\n",
    "    while i < len(expression):\n",
    "        backup = False\n",
    "        final = False\n",
    "        alpha = expression[i]\n",
    "        x = prev_state.getvalue\n",
    "        y = checkInput(alpha).getvalue\n",
    "        current_state = STATE_TABLE[x][y]\n",
    "        if current_state.getvalue == 2:\n",
    "            if lexeme in KEYWORDS:\n",
    "                tokens.append(Token(value=1, lexeme=lexeme))\n",
    "            else:\n",
    "                tokens.append(Token(value=0, lexeme=lexeme))\n",
    "            final = True\n",
    "            backup = True\n",
    "        elif current_state.getvalue == 4:\n",
    "            tokens.append(Token(value=2, lexeme=lexeme))\n",
    "            final = True\n",
    "            backup = True\n",
    "        elif current_state.getvalue == 7:\n",
    "            tokens.append(Token(value=3, lexeme=lexeme))\n",
    "            final = True\n",
    "            backup = True\n",
    "        elif current_state.getvalue == 8:\n",
    "            tokens.append(Token(value=4, lexeme=alpha))\n",
    "            final = True\n",
    "            backup = False\n",
    "        elif current_state.getvalue == 9:\n",
    "            tokens.append(Token(value=5, lexeme=alpha))\n",
    "            final = True\n",
    "            backup = False\n",
    "        elif current_state.getvalue == 10:\n",
    "            tokens.append(Token(value=6, lexeme=alpha))\n",
    "            final = True\n",
    "            backup = False\n",
    "        elif current_state.getvalue == 11:\n",
    "            raise ValueError(\"Reached Dead State\")\n",
    "        if final:\n",
    "            lexeme = ''\n",
    "            prev_state = State.INITIAL\n",
    "        else:\n",
    "            lexeme += alpha\n",
    "            prev_state = current_state\n",
    "        if not backup:\n",
    "            i += 1\n",
    "    return tokens[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression1 = [r'z', r'=', r'x',r'+',r'y']\n",
    "expression2 = ['s','i','n',r'\\theta','+','c','o','s',r'\\theta','=','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = lexer(expression1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\n",
      "=\n",
      "x\n",
      "+\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "for i in tokens:\n",
    "    print(i.lexeme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonTerminals(Enum):\n",
    "    S = 0, 'S'\n",
    "    E = 1, 'E'\n",
    "    Q = 2, 'Q'\n",
    "    T = 3, 'T'\n",
    "    R = 4, 'R'\n",
    "    F = 5, 'F'\n",
    "    NONE = 6, 'NONE'\n",
    "    \n",
    "    def __new__(cls, value, name):\n",
    "        x = object.__new__(cls)\n",
    "        x._value_ = value\n",
    "        x._name = name\n",
    "        return x\n",
    "        \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self.value\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "class Terminals(Enum):\n",
    "    IDENTIFIER = 0, 'IDENTIFIER'\n",
    "    EQUAL = 1, 'EQUAL'\n",
    "    PLUS = 2, 'PLUS'\n",
    "    MINUS = 3, 'MINUS'\n",
    "    MULTIPLY = 4, 'MULTIPLY'\n",
    "    DIVISION = 5, 'DIVISION'\n",
    "    MOD = 6, \"MOD\"\n",
    "    LEFT_ROUNDB = 7, 'LEFT_ROUNDB'\n",
    "    RIGHT_ROUNDB = 8, 'RIGHT_ROUNDB'\n",
    "    LEFT_SQUAREB = 9, 'LEFT_SQUAREB'\n",
    "    RIGHT_SQUAREB = 10, 'RIGHT_SQUAREB'\n",
    "    LEFT_CURLYB = 11, 'LEFT_CURLYB'\n",
    "    RIGHT_CURLYB = 12, 'RIGHT_CURLYB'\n",
    "    AND = 13, 'AND'\n",
    "    OR = 14, 'OR'\n",
    "    INVI_TIMES = 15, 'INVI_TIMES'\n",
    "    DOLLAR = 16, \"DOLLAR\"\n",
    "    NONE = 17, 'NONE'\n",
    "    \n",
    "    def __new__(cls, value, name):\n",
    "        x = object.__new__(cls)\n",
    "        x._value_ = value\n",
    "        x._name = name\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self.value\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "class ProdRules(Enum):\n",
    "    IEE = 0, \"i = E\"\n",
    "    E = 1, \"E\"\n",
    "    TQ = 2, \"T Q\"\n",
    "    ATQ = 3, \"+ T Q\"\n",
    "    STQ = 4, \"- T Q\"\n",
    "    FR = 5, \"F R\"\n",
    "    MFR = 6, \"* F R\"\n",
    "    DFR = 7, \"/ F R\"\n",
    "    PFR = 8, \"% F R\"\n",
    "    BEB = 9, \"( E )\"\n",
    "    I = 10, \"i\"\n",
    "    EPS = 11, \"EPSILON\"\n",
    "    INVALID = 12, \"INVALID\"\n",
    "    \n",
    "    def __new__(cls, value, name):\n",
    "        x = object.__new__(cls)\n",
    "        x._value_ = value\n",
    "        x._name = name\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def getvalue(self):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser Global Variables\n",
    "PREDICTIVE_PARSER_TABLE_DATA = [\n",
    "    [0, 12, 12, 12, 12, 12, 12, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
    "    [2, 12, 12, 12, 12, 12, 12, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
    "    [12, 12, 3, 4, 12, 12, 12, 12, 11, 12, 12, 12, 12, 12, 12, 12, 11],\n",
    "    [5, 12, 12, 12, 12, 12, 12, 5, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
    "    [12, 12, 11, 11, 6, 7, 8, 12, 11, 12, 12, 12, 12, 12, 12, 12, 11],\n",
    "    [10, 12, 12, 12, 12, 12, 12, 9, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
    "]\n",
    "\n",
    "PREDICTIVE_PARSER_TABLE = [[None for i in range(len(PREDICTIVE_PARSER_TABLE_DATA[0]))] for j in range(len(PREDICTIVE_PARSER_TABLE_DATA))]\n",
    "for i in range(len(PREDICTIVE_PARSER_TABLE_DATA)):\n",
    "    for j in range(len(PREDICTIVE_PARSER_TABLE_DATA[0])):\n",
    "        PREDICTIVE_PARSER_TABLE[i][j] = ProdRules(PREDICTIVE_PARSER_TABLE_DATA[i][j])\n",
    "\n",
    "PREDICTIVE_PARSER_TABLE = np.array(PREDICTIVE_PARSER_TABLE)\n",
    "\n",
    "LIST_TERMINALS = [i for i in Terminals if i.name not in [\"INVALID\", \"EPSILON\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTIVE_PARSER_TABLE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_terminal(lexeme):\n",
    "    if lexeme == \"i\":\n",
    "        return Terminals.IDENTIFIER\n",
    "    elif lexeme == \"=\":\n",
    "        return Terminals.EQUAL\n",
    "    elif lexeme == \"+\":\n",
    "        return Terminals.PLUS\n",
    "    elif lexeme == \"-\":\n",
    "        return Terminals.MINUS\n",
    "    elif lexeme in [\"*\", r\"\\times\", r\"\\ast\"]:\n",
    "        return Terminals.MULTIPLY\n",
    "    elif lexeme in [\"/\", r\"\\div\"]:\n",
    "        return Terminals.DIVISION\n",
    "    elif lexeme == \"%\":\n",
    "        return Terminals.MOD\n",
    "    elif lexeme in [\"(\", r\"\\(\"]:\n",
    "        return Terminals.LEFT_ROUNDB\n",
    "    elif lexeme in [\")\", r\"\\)\"]:\n",
    "        return Terminals.RIGHT_ROUNDB\n",
    "    elif lexeme == \"[\":\n",
    "        return Terminals.LEFT_SQUAREB\n",
    "    elif lexeme == \"]\":\n",
    "        return Terminals.RIGHT_SQUAREB\n",
    "    elif lexeme in [\"{\", r\"\\{\"]:\n",
    "        return Terminals.LEFT_CURLYB\n",
    "    elif lexeme in [\"}\", r\"\\}\"]:\n",
    "        return Terminals.RIGHT_CURLYB\n",
    "    elif lexeme in [\"and\", r\"\\&\"]:\n",
    "        return Terminals.AND\n",
    "    elif lexeme in [\"or\", r\"\\|\"]:\n",
    "        return Terminals.OR\n",
    "    elif lexeme == \"$\":\n",
    "        return Terminals.DOLLAR\n",
    "    else:\n",
    "        return Terminals.NONE\n",
    "\n",
    "def changeinput(token, lexeme):\n",
    "    if token == \"IDENTIFIER\":\n",
    "        return Terminals.IDENTIFIER\n",
    "    elif token == \"KEYWORD\":\n",
    "        if lexeme in [\"and\", r\"\\&\"]:\n",
    "            return Terminals.AND\n",
    "        elif lexeme in [\"or\", r\"\\|\"]:\n",
    "            return Terminals.OR\n",
    "        else:\n",
    "            return Terminals.NONE\n",
    "    elif token == \"OPERATOR\":\n",
    "        if lexeme == \"+\":\n",
    "            return Terminals.PLUS\n",
    "        elif lexeme == \"-\":\n",
    "            return Terminals.MINUS\n",
    "        elif lexeme in [\"*\", r\"\\times\", r\"\\ast\"]:\n",
    "            return Terminals.MULTIPLY\n",
    "        elif lexeme in [r\"/\", r\"\\div\"]:\n",
    "            return Terminals.DIVISION\n",
    "        elif lexeme == \"%\":\n",
    "            return Terminals.MOD\n",
    "        elif lexeme == \"$\":\n",
    "            return Terminals.DOLLAR\n",
    "        elif lexeme == \"=\":\n",
    "            return Terminals.EQUAL\n",
    "        else:\n",
    "            return Terminals.NONE\n",
    "    elif token == \"SEPARATOR\":\n",
    "        if lexeme in [\"(\", r\"\\(\"]:\n",
    "            return Terminals.LEFT_ROUNDB\n",
    "        elif lexeme in [\")\", r\"\\)\"]:\n",
    "            return Terminals.RIGHT_ROUNDB\n",
    "        elif lexeme == \"[\":\n",
    "            return Terminals.LEFT_SQUAREB\n",
    "        elif lexeme == \"]\":\n",
    "            return Terminals.RIGHT_SQUAREB\n",
    "        elif lexeme in [\"{\", r\"\\{\"]:\n",
    "            return Terminals.LEFT_CURLYB\n",
    "        elif lexeme in [\"}\", r\"\\}\"]:\n",
    "            return Terminals.RIGHT_CURLYB\n",
    "        elif lexeme == \"$\":\n",
    "            return Terminals.DOLLAR\n",
    "        elif lexeme == \";\":\n",
    "            return Terminals.DOLLAR\n",
    "        else:\n",
    "            return Terminals.NONE\n",
    "    else:\n",
    "        return Terminals.NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "#Helper function used to pop the stack\n",
    "def pop(stack):\n",
    "    temp = stack[-1]\n",
    "    del stack[-1]\n",
    "    return temp\n",
    "\n",
    "#Helper function used to push contents to the stack\n",
    "def push(stack, T):\n",
    "    stack.append(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function used to push the contents to the stack according to the Production Rules\n",
    "def pushRules(rule):\n",
    "    if rule == ProdRules(0):\n",
    "        push(stack, NonTerminals.E)\n",
    "        push(stack, Terminals.EQUAL)\n",
    "        push(stack, Terminals.IDENTIFIER)\n",
    "    elif rule == ProdRules(1):\n",
    "        push(stack, NoneTerminals.E)\n",
    "    elif rule == ProdRules(2):\n",
    "        push(stack, NonTerminals.Q)\n",
    "        push(stack, NonTerminals.T)\n",
    "    elif rule == ProdRules(3):\n",
    "        push(stack, NonTerminals.Q)\n",
    "        push(stack, NonTerminals.T)\n",
    "        push(stack,Terminals.PLUS)\n",
    "    elif rule == ProdRules(4):\n",
    "        push(stack,NonTerminals.Q)\n",
    "        push(stack,NonTerminals.T)\n",
    "        push(stack, Terminals.MINUS)\n",
    "    elif rule == ProdRules(5):\n",
    "        push(stack, NonTerminals.R)\n",
    "        push(stack, NonTerminals.F)\n",
    "    elif rule == ProdRules(6):\n",
    "        push(stack, NonTerminals.R)\n",
    "        push(stack, NonTerminals.F)\n",
    "        push(stack, Terminals.MULTIPLY)\n",
    "    elif rule == ProdRules(7):\n",
    "        push(stack, NonTerminals.R)\n",
    "        push(stack, NonTerminals.F)\n",
    "        push(stack, Terminals.DIVISION)\n",
    "    elif rule == ProdRules(8):\n",
    "        push(stack, NonTerminals.R)\n",
    "        push(stack, NonTerminals.F)\n",
    "        push(stack, Terminals.MOD)\n",
    "    elif rule == ProdRules(9):\n",
    "        push(stack, Terminals.RIGHT_ROUNDB)\n",
    "        push(stack, NonTerminals.E)\n",
    "        push(stack, Terminals.LEFT_ROUNDB)\n",
    "    elif rule == ProdRules(10):\n",
    "        push(stack, Terminals.IDENTIFIER)\n",
    "    elif rule == ProdRules(11):\n",
    "        pass                      #This statement does nothing, used so the code does not given runtime error when function is called for epsilom\n",
    "    else:\n",
    "        push(stack, NonTerminals.NONE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(tokens_lexemes):\n",
    "    tokens_lexemes.append(Token(value=4, lexeme=\"$\"))\n",
    "    per_ip = [tokens_lexemes[0]]\n",
    "    result = []\n",
    "    i = 0                                                       #used to keep track of the length of the tokens_lexemes dataframe\n",
    "    push(stack, NonTerminals.S)                                 #push S to stack for the first line\n",
    "    while i < len(tokens_lexemes) and len(stack) != 0:   #executes until the stack becomes empty and the tokens_lexmes dataframe reaches the end\n",
    "        # print(stack)\n",
    "        x = changeinput(tokens_lexemes[i].name, tokens_lexemes[i].lexeme)       #changes input to the instance of Terminals class; will be used further as column no for parser table\n",
    "        y = pop(stack)                                                            #pops the first value of the stack; will be used further as row no for parser table\n",
    "        if (x == Terminals.NONE or y == NonTerminals.NONE):                       #this will raise a Syntax Error which will be caught by Error Handling\n",
    "            raise SyntaxError(\"Token: {}\\nLexeme: {} \\nSyntax Error: Invalid Syntax\".format(tokens_lexemes[i].name, tokens_lexemes[i].lexeme))\n",
    "        elif (y in LIST_TERMINALS):                             #executes if y and x are both equal\n",
    "            if (x == y):\n",
    "                result.append(per_ip)\n",
    "                i+=1\n",
    "            else:\n",
    "                raise SyntaxError(\"Token: {}\\nLexeme: {} \\nSyntax Error: Invalid Syntax\".format(tokens_lexemes[i].name, tokens_lexemes[i].lexeme))\n",
    "            per_ip = [tokens_lexemes[i]]           #used to keep record of the token and lexeme for the current iteration; will be added to op_df when the input changes\n",
    "        else:                                                                   #executes when y and x are not equal\n",
    "            new_value = PREDICTIVE_PARSER_TABLE[y.value][x.value]                       #calculates the Production Rule according to y and x from the parser table\n",
    "            per_ip.append((y, new_value))                                          #adds the Prod Rule used to the op_ls list\n",
    "            pushRules(new_value)                                                  #pushes the contents of the Prod Rule to the stack\n",
    "    result.append(per_ip)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tree = parser(tokens)\n",
    "print(len(stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<__main__.Token at 0x1c600afd4a8>,\n",
       "  (<NonTerminals.S: 0>, <ProdRules.IEE: 0>)],\n",
       " [<__main__.Token at 0x1c600afddd8>],\n",
       " [<__main__.Token at 0x1c600afd630>,\n",
       "  (<NonTerminals.E: 1>, <ProdRules.TQ: 2>),\n",
       "  (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       "  (<NonTerminals.F: 5>, <ProdRules.I: 10>)],\n",
       " [<__main__.Token at 0x1c600afd668>,\n",
       "  (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       "  (<NonTerminals.Q: 2>, <ProdRules.ATQ: 3>)],\n",
       " [<__main__.Token at 0x1c600afd710>,\n",
       "  (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       "  (<NonTerminals.F: 5>, <ProdRules.I: 10>)],\n",
       " [<__main__.Token at 0x1c600ae7e10>,\n",
       "  (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       "  (<NonTerminals.Q: 2>, <ProdRules.EPS: 11>)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prod_rules(rule, node_parent):\n",
    "    if rule == ProdRules(0):\n",
    "        E = Node(NonTerminals.E.name, parent=node_parent)\n",
    "        EQ = Node(Terminals.EQUAL.name, parent=node_parent)\n",
    "        ID = Node(Terminals.IDENTIFIER.name, parent=node_parent)\n",
    "    elif rule == ProdRules(1):\n",
    "        E = Node(NonTerminals.E.name, parent=node_parent)    \n",
    "    elif rule == ProdRules(2):\n",
    "        Q = Node(NonTerminals.Q.name, parent=node_parent)\n",
    "        T = Node(NonTerminals.T.name, parent=node_parent)\n",
    "    elif rule == ProdRules(3):\n",
    "        Q = Node(NonTerminals.Q.name, parent=node_parent)\n",
    "        T = Node(NonTerminals.T.name, parent=node_parent)\n",
    "        PL = Node(Terminals.PLUS, parent=node_parent)\n",
    "    elif rule == ProdRules(4):\n",
    "        Q = Node(NonTerminals.Q.name, parent=node_parent)\n",
    "        T = Node(NonTerminals.T.name, parent=node_parent)\n",
    "        MI = Node(Terminals.MINUS, parent=node_parent)\n",
    "    elif rule == ProdRules(5):\n",
    "        R = Node(NonTerminals.R.name, parent=node_parent)\n",
    "        F = Node(NonTerminals.F.name, parent=node_parent)\n",
    "    elif rule == ProdRules(6):\n",
    "        R = Node(NonTerminals.R.name, parent=node_parent)\n",
    "        F = Node(NonTerminals.F.name, parent=node_parent)\n",
    "        MU = Node(Termimals.MULTIPLY, parent=node_parent)\n",
    "    elif rule == ProdRules(7):\n",
    "        R = Node(NonTerminals.R.name, parent=node_parent)\n",
    "        F = Node(NonTerminals.F.name, parent=node_parent)\n",
    "        DIV = Node(Termimals.DIVISION, parent=node_parent)\n",
    "    elif rule == ProdRules(8):\n",
    "        R = Node(NonTerminals.R.name, parent=node_parent)\n",
    "        F = Node(NonTerminals.F.name, parent=node_parent)\n",
    "        MOD = Node(Termimals.MOD, parent=node_parent)\n",
    "    elif rule == ProdRules(9):\n",
    "        RIGHTB = Node(Terminals.RIGHT_ROUNDB.name, parent=node_parent)\n",
    "        E = Node(NonTerminals.E.name, parent=node_parent)\n",
    "        LEFTB = Node(Terminals.LEFT_ROUNDB.name, parent=node_parent)\n",
    "    elif rule == ProdRules(10):\n",
    "        ID = Node(Terminals.IDENTIFIER.name, parent=node_parent)\n",
    "    elif rule == ProdRules(11):\n",
    "        pass                      #This statement does nothing, used so the code does not given runtime error when function is called for epsilom\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tree\n",
    "S = Node(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Token object at 0x000001C600AFD4A8>, (<NonTerminals.S: 0>, <ProdRules.IEE: 0>)]\n",
      "[<__main__.Token object at 0x000001C600AFDDD8>]\n",
      "[<__main__.Token object at 0x000001C600AFD630>, (<NonTerminals.E: 1>, <ProdRules.TQ: 2>), (<NonTerminals.T: 3>, <ProdRules.FR: 5>), (<NonTerminals.F: 5>, <ProdRules.I: 10>)]\n",
      "[<__main__.Token object at 0x000001C600AFD668>, (<NonTerminals.R: 4>, <ProdRules.EPS: 11>), (<NonTerminals.Q: 2>, <ProdRules.ATQ: 3>)]\n",
      "[<__main__.Token object at 0x000001C600AFD710>, (<NonTerminals.T: 3>, <ProdRules.FR: 5>), (<NonTerminals.F: 5>, <ProdRules.I: 10>)]\n",
      "[<__main__.Token object at 0x000001C600AE7E10>, (<NonTerminals.R: 4>, <ProdRules.EPS: 11>), (<NonTerminals.Q: 2>, <ProdRules.EPS: 11>)]\n"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "for i in tree:\n",
    "    if type(i[-1]) in [\"list\", \"tuple\"]:\n",
    "        for j in i[1:]:\n",
    "            node_parent = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "# print Tree\n",
    "for pre, fill, node in RenderTree(S):\n",
    "    print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: add code to construct a tree\n",
    "def parser(tokens_lexemes):\n",
    "    tokens_lexemes.append(Token(value=4, lexeme=\"$\"))\n",
    "    per_ip = [tokens_lexemes[0]]\n",
    "    result = []\n",
    "    i = 0                                                       #used to keep track of the length of the tokens_lexemes dataframe\n",
    "    push(stack, NonTerminals.S)                                #push S to stack for the first line\n",
    "    S = Node(NonTerminals.S.name)\n",
    "    nodes = []\n",
    "    while i < len(tokens_lexemes) and len(stack) != 0:   #executes until the stack becomes empty and the tokens_lexmes dataframe reaches the end\n",
    "        # print(stack)\n",
    "        x = changeinput(tokens_lexemes[i].name, tokens_lexemes[i].lexeme)       #changes input to the instance of Terminals class; will be used further as column no for parser table\n",
    "        y = pop(stack)                                                            #pops the first value of the stack; will be used further as row no for parser table\n",
    "        # tree\n",
    "        if \n",
    "        #\n",
    "        if (x == Terminals.NONE or y == NonTerminals.NONE):                       #this will raise a Syntax Error which will be caught by Error Handling\n",
    "            raise SyntaxError(\"Token: {}\\nLexeme: {} \\nSyntax Error: Invalid Syntax\".format(tokens_lexemes[i].name, tokens_lexemes[i].lexeme))\n",
    "        elif (y in LIST_TERMINALS):                             #executes if y and x are both equal\n",
    "            if (x == y):\n",
    "                result.append(per_ip)\n",
    "                i+=1\n",
    "            else:\n",
    "                raise SyntaxError(\"Token: {}\\nLexeme: {} \\nSyntax Error: Invalid Syntax\".format(tokens_lexemes[i].name, tokens_lexemes[i].lexeme))\n",
    "            per_ip = [tokens_lexemes[i]]           #used to keep record of the token and lexeme for the current iteration; will be added to op_df when the input changes\n",
    "        else:                                                                   #executes when y and x are not equal\n",
    "            new_value = PREDICTIVE_PARSER_TABLE[y.value][x.value]                       #calculates the Production Rule according to y and x from the parser table\n",
    "            per_ip.append((y, new_value))                                          #adds the Prod Rule used to the op_ls list\n",
    "            pushRules(new_value)                                                  #pushes the contents of the Prod Rule to the stack\n",
    "    result.append(per_ip)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<__main__.Token at 0x1c600afd4a8>,\n",
       "  (<NonTerminals.S: 0>, <ProdRules.IEE: 0>)],\n",
       " [<__main__.Token at 0x1c600afddd8>],\n",
       " [<__main__.Token at 0x1c600afd630>,\n",
       "  (<NonTerminals.E: 1>, <ProdRules.TQ: 2>),\n",
       "  (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       "  (<NonTerminals.F: 5>, <ProdRules.I: 10>)],\n",
       " [<__main__.Token at 0x1c600afd668>,\n",
       "  (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       "  (<NonTerminals.Q: 2>, <ProdRules.ATQ: 3>)],\n",
       " [<__main__.Token at 0x1c600afd710>,\n",
       "  (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       "  (<NonTerminals.F: 5>, <ProdRules.I: 10>)],\n",
       " [<__main__.Token at 0x1c600ae7e10>,\n",
       "  (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       "  (<NonTerminals.Q: 2>, <ProdRules.EPS: 11>)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node('/S')\n",
      "├── Node('/S/E')\n",
      "├── Node('/S/EQUAL')\n",
      "└── Node('/S/IDENTIFIER')\n"
     ]
    }
   ],
   "source": [
    "S = Node(tree[0][1][0].name)\n",
    "add_prod_rules(tree[0][1][1], node_parent=S)\n",
    "tree_stack = []\n",
    "for i in tree[1:]:\n",
    "    rules = i[1:]\n",
    "    lexeme = i[0]\n",
    "    for j in rules:\n",
    "        tree_stack.append(j)\n",
    "    \n",
    "print(RenderTree(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<NonTerminals.E: 1>, <ProdRules.TQ: 2>),\n",
       " (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       " (<NonTerminals.F: 5>, <ProdRules.I: 10>),\n",
       " (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       " (<NonTerminals.Q: 2>, <ProdRules.ATQ: 3>),\n",
       " (<NonTerminals.T: 3>, <ProdRules.FR: 5>),\n",
       " (<NonTerminals.F: 5>, <ProdRules.I: 10>),\n",
       " (<NonTerminals.R: 4>, <ProdRules.EPS: 11>),\n",
       " (<NonTerminals.Q: 2>, <ProdRules.EPS: 11>)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
